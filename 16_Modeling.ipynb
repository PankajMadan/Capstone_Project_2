{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Relevant Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)# To see all the columns of a dataframe\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce the memory usage of various Dataframes\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "       \n",
    "        1. Iterate over every column\n",
    "        2. Determine if the column is numeric\n",
    "        3. Determine if the column can be represented by an integer\n",
    "        4. Find the min and the max value\n",
    "        5. Determine and apply the smallest datatype that can fit the range of values\n",
    "\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 181.24 MB\n",
      "Memory usage after optimization is: 38.27 MB\n",
      "Decreased by 78.9%\n"
     ]
    }
   ],
   "source": [
    "# Loading reduced feature training set\n",
    "X_train = import_data('X_train_final.csv')\n",
    "y_train = pd.read_csv('y_train.final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 60.41 MB\n",
      "Memory usage after optimization is: 12.76 MB\n",
      "Decreased by 78.9%\n"
     ]
    }
   ],
   "source": [
    "# Loading reduced feature test set\n",
    "X_test = import_data('X_test_final.csv')\n",
    "y_test = pd.read_csv('y_test.final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_4: Light Gbm classifiers with Tuned Hyperparameters using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Sklearn's roc_auc_score module\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required Libraries\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Stratified K fold object\n",
    "cv_strat = StratifiedKFold(5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing  hyperparamater tuning optimizer optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing lightgbm Classifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Class weights\n",
    "cl_weight = [None,'balanced',{0:1.0,1:12},{0:1.0,1:13},{0:1.0,1:14},{0:1.0,1:15},{0:1.0,1:16},\n",
    "            {0:1.0,1:17},{0:1.0,1:18},{0:1.0,1:19},{0:1.0,1:20}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the appropriate objective function for the Light GBM classifier\n",
    "\n",
    "def objective_wrappper_lgbm(X_tr, y_tr, cls=None, cv_strat=None, cl_w=None):\n",
    "    '''\n",
    "    Optimizes classifier's cls (LightGBM here) parameters on the given training set X_tr, y_tr\n",
    "    using cross-validation cv_strat & Class weights cl_w objects.\n",
    "    \n",
    "    '''\n",
    "        \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "        'class_weight': trial.suggest_categorical('class_weight',cl_w),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 2000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 250),\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 250),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 100),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n",
    "        }\n",
    "        cls.set_params(**params)#Initializing the model with the parameters \n",
    "    \n",
    "        return np.mean(cross_val_score(cls, X_tr, y_tr, cv=cv_strat, n_jobs=5, scoring='roc_auc'))  \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the evaluation function for study's best parameters\n",
    "def study_best_score_params(X_tr, y_tr, cls, obj_func, cv_strat, cl_w, n_trials=100):\n",
    "    ''' Computes the best hyper parameters of the classsifier and returns \n",
    "    Optuna's study's best score & clasifier parameters'''\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(obj_func(X_tr, y_tr, cls, cv_strat, cl_w), n_trials)\n",
    "    best_score = study.best_value\n",
    "    best_params = study.best_params\n",
    "    return (best_score,best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the LightGBM Classifier\n",
    "lgb_c = LGBMClassifier(random_state=42,objective='binary',n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the best hyperparameters for the LightGBM classifier_1 using Reduced Feature Training Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-28 00:14:41,858]\u001b[0m A new study created in memory with name: no-name-bd44e6a1-d6d3-47c9-8d60-d8bcd0ba442f\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:16:33,594]\u001b[0m Trial 0 finished with value: 0.7576727155403674 and parameters: {'class_weight': {0: 1.0, 1: 18}, 'n_estimators': 695, 'min_child_samples': 132, 'reg_alpha': 2.3430293701805294, 'reg_lambda': 1.8647198679602717, 'num_leaves': 158, 'max_depth': 13, 'colsample_bytree': 0.7628483925715319, 'learning_rate': 0.004005083001523948}. Best is trial 0 with value: 0.7576727155403674.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:16:38,336]\u001b[0m Trial 1 finished with value: 0.7326449646003608 and parameters: {'class_weight': {0: 1.0, 1: 19}, 'n_estimators': 25, 'min_child_samples': 123, 'reg_alpha': 9.943504572731808, 'reg_lambda': 8.743105942981085, 'num_leaves': 54, 'max_depth': 45, 'colsample_bytree': 0.6497680849804933, 'learning_rate': 0.007890445950599945}. Best is trial 0 with value: 0.7576727155403674.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:16:56,709]\u001b[0m Trial 2 finished with value: 0.7398292891672751 and parameters: {'class_weight': {0: 1.0, 1: 18}, 'n_estimators': 501, 'min_child_samples': 221, 'reg_alpha': 9.760623238839418, 'reg_lambda': 0.003726228728350156, 'num_leaves': 126, 'max_depth': 2, 'colsample_bytree': 0.7235067767504603, 'learning_rate': 0.01070594056054105}. Best is trial 0 with value: 0.7576727155403674.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:17:58,977]\u001b[0m Trial 3 finished with value: 0.7601225253886637 and parameters: {'class_weight': {0: 1.0, 1: 20}, 'n_estimators': 1282, 'min_child_samples': 181, 'reg_alpha': 3.957431302532118, 'reg_lambda': 4.114512757529626, 'num_leaves': 97, 'max_depth': 5, 'colsample_bytree': 0.7450966438618558, 'learning_rate': 0.060888641182365144}. Best is trial 3 with value: 0.7601225253886637.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:21:04,382]\u001b[0m Trial 4 finished with value: 0.7539013923803648 and parameters: {'class_weight': {0: 1.0, 1: 20}, 'n_estimators': 1446, 'min_child_samples': 247, 'reg_alpha': 7.500905378873264, 'reg_lambda': 4.765872289051826, 'num_leaves': 192, 'max_depth': 44, 'colsample_bytree': 0.6540459919096898, 'learning_rate': 0.044260090197535386}. Best is trial 3 with value: 0.7601225253886637.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:22:38,212]\u001b[0m Trial 5 finished with value: 0.76577880559379 and parameters: {'class_weight': {0: 1.0, 1: 12}, 'n_estimators': 558, 'min_child_samples': 52, 'reg_alpha': 4.385763633668496, 'reg_lambda': 2.0480665258830255, 'num_leaves': 240, 'max_depth': 57, 'colsample_bytree': 0.6871737692783251, 'learning_rate': 0.018555403097121836}. Best is trial 5 with value: 0.76577880559379.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:23:46,104]\u001b[0m Trial 6 finished with value: 0.7646159742411338 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 373, 'min_child_samples': 85, 'reg_alpha': 6.732892203721985, 'reg_lambda': 0.16858175139922826, 'num_leaves': 153, 'max_depth': 91, 'colsample_bytree': 0.9355617583901481, 'learning_rate': 0.0157996523995681}. Best is trial 5 with value: 0.76577880559379.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:27:03,246]\u001b[0m Trial 7 finished with value: 0.7670012722914914 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 1202, 'min_child_samples': 208, 'reg_alpha': 1.1585620058109847, 'reg_lambda': 9.04594216957303, 'num_leaves': 228, 'max_depth': 85, 'colsample_bytree': 0.6760837652948167, 'learning_rate': 0.008051424665240276}. Best is trial 7 with value: 0.7670012722914914.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:30:51,707]\u001b[0m Trial 8 finished with value: 0.7539439179047144 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 1841, 'min_child_samples': 108, 'reg_alpha': 4.298629160822576, 'reg_lambda': 1.7397007291940247, 'num_leaves': 75, 'max_depth': 21, 'colsample_bytree': 0.7576038492593742, 'learning_rate': 0.0013180534344958235}. Best is trial 7 with value: 0.7670012722914914.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:31:07,062]\u001b[0m Trial 9 finished with value: 0.7325631892081118 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 88, 'min_child_samples': 105, 'reg_alpha': 7.391851954114732, 'reg_lambda': 0.9023434063127334, 'num_leaves': 84, 'max_depth': 18, 'colsample_bytree': 0.9392721990076471, 'learning_rate': 0.004873332376740009}. Best is trial 7 with value: 0.7670012722914914.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:32:18,151]\u001b[0m Trial 10 finished with value: 0.7367856197408201 and parameters: {'class_weight': {0: 1.0, 1: 14}, 'n_estimators': 1928, 'min_child_samples': 195, 'reg_alpha': 0.022676793290598685, 'reg_lambda': 9.468790825140026, 'num_leaves': 6, 'max_depth': 96, 'colsample_bytree': 0.611964648671064, 'learning_rate': 0.00151396240681751}. Best is trial 7 with value: 0.7670012722914914.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:35:05,843]\u001b[0m Trial 11 finished with value: 0.756966929000733 and parameters: {'class_weight': {0: 1.0, 1: 12}, 'n_estimators': 1086, 'min_child_samples': 31, 'reg_alpha': 0.1341565837012546, 'reg_lambda': 7.315430789332087, 'num_leaves': 234, 'max_depth': 74, 'colsample_bytree': 0.8434925972192777, 'learning_rate': 0.025658470346485048}. Best is trial 7 with value: 0.7670012722914914.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:37:09,988]\u001b[0m Trial 12 finished with value: 0.7627345327301864 and parameters: {'class_weight': {0: 1.0, 1: 16}, 'n_estimators': 797, 'min_child_samples': 20, 'reg_alpha': 2.0059462389886518, 'reg_lambda': 6.492265715387028, 'num_leaves': 243, 'max_depth': 68, 'colsample_bytree': 0.682182295552292, 'learning_rate': 0.02036125084340301}. Best is trial 7 with value: 0.7670012722914914.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:42:14,697]\u001b[0m Trial 13 finished with value: 0.7644382510984384 and parameters: {'class_weight': {0: 1.0, 1: 12}, 'n_estimators': 1551, 'min_child_samples': 59, 'reg_alpha': 1.9818883053882483, 'reg_lambda': 3.0391834627893566, 'num_leaves': 209, 'max_depth': 65, 'colsample_bytree': 0.8433760151118735, 'learning_rate': 0.0031226342100141875}. Best is trial 7 with value: 0.7670012722914914.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:44:47,729]\u001b[0m Trial 14 finished with value: 0.7671802717146841 and parameters: {'class_weight': 'balanced', 'n_estimators': 929, 'min_child_samples': 155, 'reg_alpha': 5.277738017898159, 'reg_lambda': 7.200253384552501, 'num_leaves': 247, 'max_depth': 82, 'colsample_bytree': 0.6000592330138645, 'learning_rate': 0.008470674508087254}. Best is trial 14 with value: 0.7671802717146841.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:47:22,958]\u001b[0m Trial 15 finished with value: 0.7670065582762706 and parameters: {'class_weight': 'balanced', 'n_estimators': 1043, 'min_child_samples': 173, 'reg_alpha': 5.652682288260252, 'reg_lambda': 7.43322313368233, 'num_leaves': 197, 'max_depth': 84, 'colsample_bytree': 0.6007624145212267, 'learning_rate': 0.006840459107602477}. Best is trial 14 with value: 0.7671802717146841.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:49:26,927]\u001b[0m Trial 16 finished with value: 0.7574319751844868 and parameters: {'class_weight': 'balanced', 'n_estimators': 901, 'min_child_samples': 162, 'reg_alpha': 5.858100482078546, 'reg_lambda': 6.522610796324771, 'num_leaves': 186, 'max_depth': 82, 'colsample_bytree': 0.6021138720438519, 'learning_rate': 0.002354143231685856}. Best is trial 14 with value: 0.7671802717146841.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:51:46,227]\u001b[0m Trial 17 finished with value: 0.766023082394332 and parameters: {'class_weight': 'balanced', 'n_estimators': 999, 'min_child_samples': 154, 'reg_alpha': 8.451237098842082, 'reg_lambda': 7.661800675189641, 'num_leaves': 170, 'max_depth': 100, 'colsample_bytree': 0.6045982519108042, 'learning_rate': 0.005926484628236033}. Best is trial 14 with value: 0.7671802717146841.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:52:44,443]\u001b[0m Trial 18 finished with value: 0.762168676132175 and parameters: {'class_weight': 'balanced', 'n_estimators': 306, 'min_child_samples': 231, 'reg_alpha': 5.24267760217803, 'reg_lambda': 5.866541241284011, 'num_leaves': 212, 'max_depth': 77, 'colsample_bytree': 0.8205285723315643, 'learning_rate': 0.012729853559567779}. Best is trial 14 with value: 0.7671802717146841.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 00:57:08,785]\u001b[0m Trial 19 finished with value: 0.7604626023791606 and parameters: {'class_weight': {0: 1.0, 1: 17}, 'n_estimators': 1612, 'min_child_samples': 160, 'reg_alpha': 5.993025768170225, 'reg_lambda': 8.021651026446236, 'num_leaves': 126, 'max_depth': 30, 'colsample_bytree': 0.8939945967785394, 'learning_rate': 0.0022171692231181704}. Best is trial 14 with value: 0.7671802717146841.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-28 01:00:58,179]\u001b[0m Trial 20 finished with value: 0.7649470063402004 and parameters: {'class_weight': None, 'n_estimators': 1194, 'min_child_samples': 182, 'reg_alpha': 3.204521658106843, 'reg_lambda': 5.784251801656469, 'num_leaves': 207, 'max_depth': 59, 'colsample_bytree': 0.990479769723445, 'learning_rate': 0.005999824619983893}. Best is trial 14 with value: 0.7671802717146841.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:04:29,644]\u001b[0m Trial 21 finished with value: 0.7675424057666671 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 1333, 'min_child_samples': 209, 'reg_alpha': 5.371928310382926, 'reg_lambda': 9.855672244353572, 'num_leaves': 228, 'max_depth': 85, 'colsample_bytree': 0.6448919770743746, 'learning_rate': 0.007926009764444197}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:07:52,113]\u001b[0m Trial 22 finished with value: 0.7569794800038225 and parameters: {'class_weight': 'balanced', 'n_estimators': 1431, 'min_child_samples': 150, 'reg_alpha': 5.233014576413743, 'reg_lambda': 9.793826110633823, 'num_leaves': 250, 'max_depth': 90, 'colsample_bytree': 0.6350800406079322, 'learning_rate': 0.03615763964078542}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:10:22,775]\u001b[0m Trial 23 finished with value: 0.7675023421107989 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 970, 'min_child_samples': 238, 'reg_alpha': 6.305811836319498, 'reg_lambda': 8.548268900260554, 'num_leaves': 219, 'max_depth': 98, 'colsample_bytree': 0.6310200146596499, 'learning_rate': 0.009313031711332723}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:12:41,166]\u001b[0m Trial 24 finished with value: 0.7668936078153529 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 781, 'min_child_samples': 250, 'reg_alpha': 6.678895517787275, 'reg_lambda': 8.505386475066274, 'num_leaves': 250, 'max_depth': 99, 'colsample_bytree': 0.7014305832900886, 'learning_rate': 0.01080727391911754}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:17:34,872]\u001b[0m Trial 25 finished with value: 0.766518073056614 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 1732, 'min_child_samples': 233, 'reg_alpha': 8.10070824160807, 'reg_lambda': 9.901522823321919, 'num_leaves': 218, 'max_depth': 74, 'colsample_bytree': 0.6349763068083624, 'learning_rate': 0.003633667297253831}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:20:18,976]\u001b[0m Trial 26 finished with value: 0.7659816019813694 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 1341, 'min_child_samples': 199, 'reg_alpha': 6.6324118929951155, 'reg_lambda': 8.48933072563529, 'num_leaves': 178, 'max_depth': 95, 'colsample_bytree': 0.6259733586537891, 'learning_rate': 0.01430258485455387}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:22:28,025]\u001b[0m Trial 27 finished with value: 0.7432803191966391 and parameters: {'class_weight': None, 'n_estimators': 909, 'min_child_samples': 207, 'reg_alpha': 3.640622599388916, 'reg_lambda': 6.862066193860113, 'num_leaves': 225, 'max_depth': 100, 'colsample_bytree': 0.720893883599367, 'learning_rate': 0.09874457523587415}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:24:30,383]\u001b[0m Trial 28 finished with value: 0.7646232966914719 and parameters: {'class_weight': {0: 1.0, 1: 14}, 'n_estimators': 637, 'min_child_samples': 222, 'reg_alpha': 4.727767941741292, 'reg_lambda': 9.976736000673602, 'num_leaves': 229, 'max_depth': 91, 'colsample_bytree': 0.7893136192209386, 'learning_rate': 0.008026135429050249}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:26:29,006]\u001b[0m Trial 29 finished with value: 0.7596467154478901 and parameters: {'class_weight': {0: 1.0, 1: 17}, 'n_estimators': 1124, 'min_child_samples': 140, 'reg_alpha': 3.0309772813216265, 'reg_lambda': 8.211968179560259, 'num_leaves': 161, 'max_depth': 68, 'colsample_bytree': 0.6677852764093529, 'learning_rate': 0.0292117810535237}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:28:52,961]\u001b[0m Trial 30 finished with value: 0.7612678368061434 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 768, 'min_child_samples': 239, 'reg_alpha': 8.956409317943436, 'reg_lambda': 9.200788323708194, 'num_leaves': 250, 'max_depth': 80, 'colsample_bytree': 0.7237055013223787, 'learning_rate': 0.004447209898533035}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:31:17,030]\u001b[0m Trial 31 finished with value: 0.7667860675560547 and parameters: {'class_weight': 'balanced', 'n_estimators': 1013, 'min_child_samples': 185, 'reg_alpha': 5.887295090860015, 'reg_lambda': 7.343719088540286, 'num_leaves': 199, 'max_depth': 84, 'colsample_bytree': 0.6068695562283827, 'learning_rate': 0.0064993993033236495}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:33:36,397]\u001b[0m Trial 32 finished with value: 0.7671399784399651 and parameters: {'class_weight': {0: 1.0, 1: 19}, 'n_estimators': 929, 'min_child_samples': 169, 'reg_alpha': 5.314963423561661, 'reg_lambda': 5.7655095542782355, 'num_leaves': 194, 'max_depth': 90, 'colsample_bytree': 0.6489392419651172, 'learning_rate': 0.009419766387090142}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:35:30,022]\u001b[0m Trial 33 finished with value: 0.7672105901917791 and parameters: {'class_weight': {0: 1.0, 1: 19}, 'n_estimators': 885, 'min_child_samples': 218, 'reg_alpha': 4.936964173957857, 'reg_lambda': 5.426937646205913, 'num_leaves': 145, 'max_depth': 89, 'colsample_bytree': 0.6508878920899679, 'learning_rate': 0.009506760482052158}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:38:20,195]\u001b[0m Trial 34 finished with value: 0.767252908095711 and parameters: {'class_weight': {0: 1.0, 1: 19}, 'n_estimators': 1307, 'min_child_samples': 216, 'reg_alpha': 4.851785876967187, 'reg_lambda': 4.21122323497791, 'num_leaves': 147, 'max_depth': 46, 'colsample_bytree': 0.654566943252562, 'learning_rate': 0.010379216420905685}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:41:09,648]\u001b[0m Trial 35 finished with value: 0.7661662805735012 and parameters: {'class_weight': {0: 1.0, 1: 19}, 'n_estimators': 1464, 'min_child_samples': 217, 'reg_alpha': 4.657282288173214, 'reg_lambda': 3.7686231024695713, 'num_leaves': 143, 'max_depth': 42, 'colsample_bytree': 0.7043411457083577, 'learning_rate': 0.011873338782936269}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:43:38,216]\u001b[0m Trial 36 finished with value: 0.7648176063613473 and parameters: {'class_weight': {0: 1.0, 1: 19}, 'n_estimators': 1648, 'min_child_samples': 246, 'reg_alpha': 6.3363060150037525, 'reg_lambda': 4.649752992336135, 'num_leaves': 113, 'max_depth': 35, 'colsample_bytree': 0.6573082253739377, 'learning_rate': 0.01729775909034528}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:46:26,962]\u001b[0m Trial 37 finished with value: 0.7664324324350388 and parameters: {'class_weight': {0: 1.0, 1: 18}, 'n_estimators': 1300, 'min_child_samples': 219, 'reg_alpha': 3.858291806488547, 'reg_lambda': 3.148518684312876, 'num_leaves': 140, 'max_depth': 50, 'colsample_bytree': 0.6283719085070093, 'learning_rate': 0.004867679635074355}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:47:18,273]\u001b[0m Trial 38 finished with value: 0.7654727392473571 and parameters: {'class_weight': {0: 1.0, 1: 19}, 'n_estimators': 1212, 'min_child_samples': 198, 'reg_alpha': 2.877675103944578, 'reg_lambda': 3.980266952757144, 'num_leaves': 8, 'max_depth': 58, 'colsample_bytree': 0.7314374523030656, 'learning_rate': 0.022811387197432392}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:49:49,696]\u001b[0m Trial 39 finished with value: 0.7671133756415662 and parameters: {'class_weight': {0: 1.0, 1: 19}, 'n_estimators': 1364, 'min_child_samples': 249, 'reg_alpha': 7.1261124541656065, 'reg_lambda': 2.9997192114738045, 'num_leaves': 110, 'max_depth': 39, 'colsample_bytree': 0.6963062905439426, 'learning_rate': 0.010585224930182059}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-28 01:50:52,858]\u001b[0m Trial 40 finished with value: 0.7466885415930347 and parameters: {'class_weight': {0: 1.0, 1: 19}, 'n_estimators': 484, 'min_child_samples': 212, 'reg_alpha': 4.182188477397222, 'reg_lambda': 5.136740398225163, 'num_leaves': 59, 'max_depth': 48, 'colsample_bytree': 0.7750980881201373, 'learning_rate': 0.003258359145538698}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:53:24,026]\u001b[0m Trial 41 finished with value: 0.7673566047915893 and parameters: {'class_weight': {0: 1.0, 1: 16}, 'n_estimators': 1171, 'min_child_samples': 124, 'reg_alpha': 4.881840143403759, 'reg_lambda': 5.112668178931702, 'num_leaves': 155, 'max_depth': 54, 'colsample_bytree': 0.6493329332052672, 'learning_rate': 0.008022585467796278}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:55:30,135]\u001b[0m Trial 42 finished with value: 0.7657546068639969 and parameters: {'class_weight': {0: 1.0, 1: 16}, 'n_estimators': 1163, 'min_child_samples': 123, 'reg_alpha': 4.580315414141537, 'reg_lambda': 5.177969476053277, 'num_leaves': 146, 'max_depth': 30, 'colsample_bytree': 0.6522942170066434, 'learning_rate': 0.013141513137682559}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 01:57:35,230]\u001b[0m Trial 43 finished with value: 0.7631327168623342 and parameters: {'class_weight': {0: 1.0, 1: 20}, 'n_estimators': 1263, 'min_child_samples': 96, 'reg_alpha': 3.5748068931767345, 'reg_lambda': 4.370806833244311, 'num_leaves': 162, 'max_depth': 8, 'colsample_bytree': 0.6719135205852789, 'learning_rate': 0.009585896354221963}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 02:00:07,142]\u001b[0m Trial 44 finished with value: 0.7647350099140369 and parameters: {'class_weight': {0: 1.0, 1: 16}, 'n_estimators': 1522, 'min_child_samples': 227, 'reg_alpha': 4.951174931137456, 'reg_lambda': 3.607262573183381, 'num_leaves': 133, 'max_depth': 52, 'colsample_bytree': 0.6422199462225748, 'learning_rate': 0.0169558418433412}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 02:02:11,355]\u001b[0m Trial 45 finished with value: 0.7670310838449054 and parameters: {'class_weight': {0: 1.0, 1: 16}, 'n_estimators': 1101, 'min_child_samples': 76, 'reg_alpha': 6.284991741350162, 'reg_lambda': 2.2471534925897565, 'num_leaves': 111, 'max_depth': 63, 'colsample_bytree': 0.6189237894154888, 'learning_rate': 0.00684748708250987}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 02:05:33,920]\u001b[0m Trial 46 finished with value: 0.7671049997812622 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 1373, 'min_child_samples': 116, 'reg_alpha': 4.213875381676592, 'reg_lambda': 5.470221537010271, 'num_leaves': 180, 'max_depth': 54, 'colsample_bytree': 0.6660319694433585, 'learning_rate': 0.005337206622607726}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 02:06:52,522]\u001b[0m Trial 47 finished with value: 0.7647269133624653 and parameters: {'class_weight': {0: 1.0, 1: 18}, 'n_estimators': 685, 'min_child_samples': 191, 'reg_alpha': 7.621703943843137, 'reg_lambda': 4.591107394931747, 'num_leaves': 95, 'max_depth': 96, 'colsample_bytree': 0.6810955344671991, 'learning_rate': 0.007924060911413858}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 02:09:04,419]\u001b[0m Trial 48 finished with value: 0.7605873256909153 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 820, 'min_child_samples': 137, 'reg_alpha': 5.5815397079993465, 'reg_lambda': 6.296762658589051, 'num_leaves': 158, 'max_depth': 87, 'colsample_bytree': 0.7468414819273148, 'learning_rate': 0.004094213588719717}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n",
      "\u001b[32m[I 2020-12-28 02:11:51,583]\u001b[0m Trial 49 finished with value: 0.7662687296544238 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 1265, 'min_child_samples': 239, 'reg_alpha': 7.0894345848289255, 'reg_lambda': 8.909654365540048, 'num_leaves': 172, 'max_depth': 73, 'colsample_bytree': 0.6898417030572375, 'learning_rate': 0.014089063251638832}. Best is trial 21 with value: 0.7675424057666671.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Extracting the best model parameters and best study score\n",
    "best_study_score,best_study_params = study_best_score_params(X_train.values, y_train.values, lgb_c, objective_wrappper_lgbm, cv_strat,\n",
    "                                                            cl_weight, n_trials=50)\n",
    "# Used X_train.values & y_train.values as the some feature names had JSON characters , which were causing trouble while\n",
    "# code execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best roc_auc_score for the study is:  0.7675424057666671\n"
     ]
    }
   ],
   "source": [
    "print('The best roc_auc_score for the study is: ',best_study_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The best study parameters for the classifier are: ', {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 1333, 'min_child_samples': 209, 'reg_alpha': 5.371928310382926, 'reg_lambda': 9.855672244353572, 'num_leaves': 228, 'max_depth': 85, 'colsample_bytree': 0.6448919770743746, 'learning_rate': 0.007926009764444197})\n"
     ]
    }
   ],
   "source": [
    "print('The best study parameters for the classifier are: ',best_study_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the best tuned LightGbm model by setting best study parameters.\n",
    "lgb_c = lgb_c.set_params(**best_study_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(class_weight={0: 1.0, 1: 15},\n",
       "               colsample_bytree=0.6448919770743746,\n",
       "               learning_rate=0.007926009764444197, max_depth=85,\n",
       "               min_child_samples=209, n_estimators=1333, n_jobs=5,\n",
       "               num_leaves=228, objective='binary', random_state=42,\n",
       "               reg_alpha=5.371928310382926, reg_lambda=9.855672244353572)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the best tuned lightgbm model on the Reduced feature training set.\n",
    "lgb_c.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to calculate the roc_auc score for the feature sets\n",
    "def cal_roc_auc(X, y, cls, f_set, t_set, model_name):\n",
    "    ''' Calculates the roc auc score using the best study parameters \n",
    "        f_set : String: specifies 'full feature', 'Reduced feature'\n",
    "        t_set: String: specifies 'training', 'test'\n",
    "        model_name: String: specifies Name of the model '''\n",
    "        \n",
    "    y_pred = cls.predict_proba(X)\n",
    "    print('The roc_auc_score for the {} {} set using the best {} is '.format(f_set,t_set,model_name),roc_auc_score(y,y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the Reduced feature training set using the best Light Gbm is  0.9516343112915224\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Reduced feature training set roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_train.values, y_train, lgb_c, 'Reduced feature', 'training', 'Light Gbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the Reduced feature test set using the best Light Gbm is  0.7725786275246422\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Reduced feature test set roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_test.values, y_test, lgb_c, 'Reduced feature', 'test','Light Gbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating R_R ratio for the Light GBM Classifier_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the CV scores using sklearn's cross_val_score\n",
    "score_Light_Gbm_1 = cross_val_score(lgb_c, X_train.values, y_train, cv=cv_strat, n_jobs=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward associated with the Light GMB Classifier_1 using roc_auc metric is:  0.7675424057666671\n"
     ]
    }
   ],
   "source": [
    "print('The reward associated with the Light GMB Classifier_1 using roc_auc metric is: ',np.mean(score_Light_Gbm_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risk associated with the Light GMB Classifier_1 using roc_auc metric is:  0.004609725931915861\n"
     ]
    }
   ],
   "source": [
    "print('The risk associated with the Light GMB Classifier_1 using roc_auc metric is: ',np.std(score_Light_Gbm_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_R_Ratio_Light_Gbm_1 = np.mean(score_Light_Gbm_1)/np.std(score_Light_Gbm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward risk ratio for the best Light Gbm Classifier using roc_auc metric is:  166.50499771635376\n"
     ]
    }
   ],
   "source": [
    "print('The reward risk ratio for the best Light Gbm Classifier using roc_auc metric is: ',R_R_Ratio_Light_Gbm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold CV roc_auc scores for the light_gbm classifier are:  [0.76296609 0.76266868 0.77517289 0.7693666  0.76753777]\n"
     ]
    }
   ],
   "source": [
    "print('5 fold CV roc_auc scores for the light_gbm classifier are: ',score_Light_Gbm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Light_Gbm_1.joblib']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the Reduced feature set best Light Gbm Classifier_1\n",
    "import joblib\n",
    "joblib.dump(lgb_c,'Light_Gbm_1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R_R Ratio for the Light Gbm classifier_1 using roc_auc metric is:  166.50499771635376"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation(s):\n",
    "### 1) Of all the models fitted till now, lgb classifier_1 has the best test set roc_auc score as well as the R_R ratio. \n",
    "### 2) But clearly lgb classifier_1 has overfitted the dataset , as there is a large difference between the training set and test set roc_auc score. This overfitting is typical of most boosting classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Gbm Classifier_2 : A more regularized version of the previous light gbm model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the appropriate objective function for the more regularized Light GBM classifier\n",
    "\n",
    "def objective_wrappper_lgbm(X_tr, y_tr, cls=None, cv_strat=None, cl_w=None):\n",
    "    '''\n",
    "    Optimizes classifier's cls (LightGBM here) parameters on the given training set X_tr, y_tr\n",
    "    using cross-validation cv_strat & Class weights cl_w objects.\n",
    "        \n",
    "    '''\n",
    "        \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "        'class_weight': trial.suggest_categorical('class_weight',cl_w),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1200),# More Regularization\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 150, 250),# More Regularization\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha', 10, 15), # More Regularization\n",
    "        'reg_lambda': trial.suggest_uniform('reg_lambda', 10, 15), # More Regularization\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 175),# More Regularization\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 75), # More Regularization\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1)\n",
    "        }\n",
    "        cls.set_params(**params)#Initializing the model with the parameters \n",
    "    \n",
    "        return np.mean(cross_val_score(cls, X_tr, y_tr, cv=cv_strat, n_jobs=5, scoring='roc_auc'))  \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the evaluation function for study's best parameters\n",
    "def study_best_score_params(X_tr, y_tr, cls, obj_func, cv_strat, cl_w, n_trials=100):\n",
    "    ''' Computes the best hyper parameters of the classsifier and returns \n",
    "    Optuna's study's best score & clasifier parameters'''\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(obj_func(X_tr, y_tr, cls, cv_strat, cl_w), n_trials)\n",
    "    best_score = study.best_value\n",
    "    best_params = study.best_params\n",
    "    return (best_score,best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the LightGBM Classifier\n",
    "lgb_c = LGBMClassifier(random_state=42, objective='binary', n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the best hyperparameters for the Light GBM classifier_2 using Reduced Feature Training Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-29 00:55:17,563]\u001b[0m A new study created in memory with name: no-name-c3fbece1-4af2-4fc5-90f5-f1df582e037e\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 00:56:45,218]\u001b[0m Trial 0 finished with value: 0.7657969584471875 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 742, 'min_child_samples': 180, 'reg_alpha': 13.215252563900878, 'reg_lambda': 11.805865838506026, 'num_leaves': 92, 'max_depth': 50, 'colsample_bytree': 0.9574888587995646, 'learning_rate': 0.022330012555304646}. Best is trial 0 with value: 0.7657969584471875.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 00:56:53,747]\u001b[0m Trial 1 finished with value: 0.7428068313833717 and parameters: {'class_weight': 'balanced', 'n_estimators': 45, 'min_child_samples': 209, 'reg_alpha': 13.137942508776664, 'reg_lambda': 13.082211190821157, 'num_leaves': 129, 'max_depth': 11, 'colsample_bytree': 0.7757218805719028, 'learning_rate': 0.016394553189848563}. Best is trial 0 with value: 0.7657969584471875.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 00:59:01,591]\u001b[0m Trial 2 finished with value: 0.746320913082233 and parameters: {'class_weight': {0: 1.0, 1: 19}, 'n_estimators': 816, 'min_child_samples': 155, 'reg_alpha': 10.658907021208822, 'reg_lambda': 12.405247284729725, 'num_leaves': 128, 'max_depth': 30, 'colsample_bytree': 0.8641019712072323, 'learning_rate': 0.0015224391205276833}. Best is trial 0 with value: 0.7657969584471875.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 00:59:57,434]\u001b[0m Trial 3 finished with value: 0.7678642284061652 and parameters: {'class_weight': {0: 1.0, 1: 14}, 'n_estimators': 952, 'min_child_samples': 169, 'reg_alpha': 14.144521236041252, 'reg_lambda': 10.652966656781794, 'num_leaves': 28, 'max_depth': 63, 'colsample_bytree': 0.608334987866598, 'learning_rate': 0.019765247532750833}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:00:22,342]\u001b[0m Trial 4 finished with value: 0.7666408563176211 and parameters: {'class_weight': {0: 1.0, 1: 12}, 'n_estimators': 414, 'min_child_samples': 205, 'reg_alpha': 13.902340632846402, 'reg_lambda': 11.233368887294517, 'num_leaves': 17, 'max_depth': 55, 'colsample_bytree': 0.6297510315319487, 'learning_rate': 0.051169514060025845}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:00:55,202]\u001b[0m Trial 5 finished with value: 0.7609643772076635 and parameters: {'class_weight': None, 'n_estimators': 240, 'min_child_samples': 168, 'reg_alpha': 10.49347941122512, 'reg_lambda': 11.884117841182753, 'num_leaves': 165, 'max_depth': 33, 'colsample_bytree': 0.7073182262427555, 'learning_rate': 0.09017266900152258}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:02:23,931]\u001b[0m Trial 6 finished with value: 0.7624230748431428 and parameters: {'class_weight': {0: 1.0, 1: 14}, 'n_estimators': 645, 'min_child_samples': 165, 'reg_alpha': 12.133815121756482, 'reg_lambda': 13.835021342725645, 'num_leaves': 92, 'max_depth': 14, 'colsample_bytree': 0.8738289521458324, 'learning_rate': 0.006877050418457118}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:04:13,132]\u001b[0m Trial 7 finished with value: 0.7632815700842673 and parameters: {'class_weight': {0: 1.0, 1: 14}, 'n_estimators': 921, 'min_child_samples': 164, 'reg_alpha': 14.215858932784215, 'reg_lambda': 11.283592536100247, 'num_leaves': 124, 'max_depth': 42, 'colsample_bytree': 0.8356589202444975, 'learning_rate': 0.03149588829488464}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:04:27,436]\u001b[0m Trial 8 finished with value: 0.756963529075574 and parameters: {'class_weight': {0: 1.0, 1: 16}, 'n_estimators': 157, 'min_child_samples': 230, 'reg_alpha': 10.246155381247144, 'reg_lambda': 13.722573704963017, 'num_leaves': 20, 'max_depth': 75, 'colsample_bytree': 0.6919460536967588, 'learning_rate': 0.02952538442809845}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:06:21,010]\u001b[0m Trial 9 finished with value: 0.7656620304426698 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 810, 'min_child_samples': 198, 'reg_alpha': 10.805580455910707, 'reg_lambda': 12.956284515393971, 'num_leaves': 146, 'max_depth': 56, 'colsample_bytree': 0.8926224418955295, 'learning_rate': 0.020034825245050975}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:07:55,905]\u001b[0m Trial 10 finished with value: 0.7643176047481524 and parameters: {'class_weight': {0: 1.0, 1: 17}, 'n_estimators': 1200, 'min_child_samples': 188, 'reg_alpha': 14.853673131274094, 'reg_lambda': 10.047866038429898, 'num_leaves': 46, 'max_depth': 75, 'colsample_bytree': 0.6054261050802805, 'learning_rate': 0.005101427410891104}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:08:06,889]\u001b[0m Trial 11 finished with value: 0.7552082892625949 and parameters: {'class_weight': {0: 1.0, 1: 12}, 'n_estimators': 428, 'min_child_samples': 218, 'reg_alpha': 14.255358087410524, 'reg_lambda': 10.264249080974716, 'num_leaves': 2, 'max_depth': 63, 'colsample_bytree': 0.6210062526570524, 'learning_rate': 0.0898468525823423}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:09:15,168]\u001b[0m Trial 12 finished with value: 0.7622145624770231 and parameters: {'class_weight': {0: 1.0, 1: 20}, 'n_estimators': 1118, 'min_child_samples': 248, 'reg_alpha': 14.94946140822076, 'reg_lambda': 10.722008575084148, 'num_leaves': 45, 'max_depth': 66, 'colsample_bytree': 0.6649600454057754, 'learning_rate': 0.05341900453331039}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:09:52,590]\u001b[0m Trial 13 finished with value: 0.7581706989217596 and parameters: {'class_weight': {0: 1.0, 1: 12}, 'n_estimators': 438, 'min_child_samples': 190, 'reg_alpha': 13.789711214789754, 'reg_lambda': 10.909140873944478, 'num_leaves': 41, 'max_depth': 48, 'colsample_bytree': 0.7564264790545967, 'learning_rate': 0.008581806859872951}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:10:06,468]\u001b[0m Trial 14 finished with value: 0.7509851998236199 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 481, 'min_child_samples': 225, 'reg_alpha': 12.039479460017693, 'reg_lambda': 11.374623649897407, 'num_leaves': 2, 'max_depth': 64, 'colsample_bytree': 0.600164867003923, 'learning_rate': 0.05213295162304642}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:11:55,997]\u001b[0m Trial 15 finished with value: 0.7592404181655474 and parameters: {'class_weight': {0: 1.0, 1: 18}, 'n_estimators': 1030, 'min_child_samples': 207, 'reg_alpha': 12.994079285129656, 'reg_lambda': 14.853145944558882, 'num_leaves': 67, 'max_depth': 57, 'colsample_bytree': 0.6531106615186908, 'learning_rate': 0.0035145923841890026}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:12:14,921]\u001b[0m Trial 16 finished with value: 0.7517619288408202 and parameters: {'class_weight': {0: 1.0, 1: 12}, 'n_estimators': 250, 'min_child_samples': 239, 'reg_alpha': 13.891455886515327, 'reg_lambda': 10.408171277205836, 'num_leaves': 21, 'max_depth': 75, 'colsample_bytree': 0.7254641043247103, 'learning_rate': 0.013284495572267477}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:13:04,747]\u001b[0m Trial 17 finished with value: 0.7644936402330004 and parameters: {'class_weight': {0: 1.0, 1: 14}, 'n_estimators': 572, 'min_child_samples': 150, 'reg_alpha': 14.462511120101741, 'reg_lambda': 11.146102099398211, 'num_leaves': 68, 'max_depth': 40, 'colsample_bytree': 0.6510840167091266, 'learning_rate': 0.050939021435672575}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:13:46,655]\u001b[0m Trial 18 finished with value: 0.7667172171162283 and parameters: {'class_weight': {0: 1.0, 1: 12}, 'n_estimators': 1004, 'min_child_samples': 173, 'reg_alpha': 11.432091681277116, 'reg_lambda': 12.059125177153625, 'num_leaves': 19, 'max_depth': 23, 'colsample_bytree': 0.607253915936388, 'learning_rate': 0.042648196926406916}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:15:35,792]\u001b[0m Trial 19 finished with value: 0.7656081910694288 and parameters: {'class_weight': {0: 1.0, 1: 20}, 'n_estimators': 970, 'min_child_samples': 177, 'reg_alpha': 11.279992820111453, 'reg_lambda': 11.990170314520453, 'num_leaves': 66, 'max_depth': 21, 'colsample_bytree': 0.9982523181148716, 'learning_rate': 0.01121096390905803}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-29 01:16:45,502]\u001b[0m Trial 20 finished with value: 0.7658235488797565 and parameters: {'class_weight': {0: 1.0, 1: 14}, 'n_estimators': 1159, 'min_child_samples': 157, 'reg_alpha': 11.413233642148334, 'reg_lambda': 12.57576219574895, 'num_leaves': 33, 'max_depth': 22, 'colsample_bytree': 0.7415456532250405, 'learning_rate': 0.030628097188775343}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:17:19,584]\u001b[0m Trial 21 finished with value: 0.7666741192614777 and parameters: {'class_weight': {0: 1.0, 1: 12}, 'n_estimators': 887, 'min_child_samples': 177, 'reg_alpha': 12.605330250526153, 'reg_lambda': 11.553929031524818, 'num_leaves': 14, 'max_depth': 5, 'colsample_bytree': 0.60138059303007, 'learning_rate': 0.06410606944257212}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:17:48,776]\u001b[0m Trial 22 finished with value: 0.766583857283782 and parameters: {'class_weight': {0: 1.0, 1: 12}, 'n_estimators': 1052, 'min_child_samples': 176, 'reg_alpha': 12.438118398958881, 'reg_lambda': 11.649441749249764, 'num_leaves': 4, 'max_depth': 5, 'colsample_bytree': 0.60485296964875, 'learning_rate': 0.07825610536119627}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:18:41,791]\u001b[0m Trial 23 finished with value: 0.7666366161283623 and parameters: {'class_weight': {0: 1.0, 1: 12}, 'n_estimators': 870, 'min_child_samples': 186, 'reg_alpha': 11.72850147271326, 'reg_lambda': 10.680406268072607, 'num_leaves': 29, 'max_depth': 6, 'colsample_bytree': 0.6830969387287407, 'learning_rate': 0.04108831907808329}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:19:07,368]\u001b[0m Trial 24 finished with value: 0.7668128288651683 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 705, 'min_child_samples': 171, 'reg_alpha': 12.746007348021728, 'reg_lambda': 12.30161844068809, 'num_leaves': 10, 'max_depth': 22, 'colsample_bytree': 0.6005789776675435, 'learning_rate': 0.06972586217304347}. Best is trial 3 with value: 0.7678642284061652.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:19:54,006]\u001b[0m Trial 25 finished with value: 0.768080775505045 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 676, 'min_child_samples': 167, 'reg_alpha': 11.102817382245416, 'reg_lambda': 12.335917702471356, 'num_leaves': 55, 'max_depth': 25, 'colsample_bytree': 0.6409698173169934, 'learning_rate': 0.022194354272829574}. Best is trial 25 with value: 0.768080775505045.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:20:52,257]\u001b[0m Trial 26 finished with value: 0.7676523919803635 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 678, 'min_child_samples': 150, 'reg_alpha': 12.620223701803651, 'reg_lambda': 13.545343626490626, 'num_leaves': 60, 'max_depth': 31, 'colsample_bytree': 0.640060620959506, 'learning_rate': 0.020540165318679686}. Best is trial 25 with value: 0.768080775505045.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:21:50,465]\u001b[0m Trial 27 finished with value: 0.7673486795325198 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 567, 'min_child_samples': 151, 'reg_alpha': 13.493111877703205, 'reg_lambda': 14.67531456893429, 'num_leaves': 58, 'max_depth': 32, 'colsample_bytree': 0.6400062586179063, 'learning_rate': 0.015986131153482512}. Best is trial 25 with value: 0.768080775505045.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:23:03,646]\u001b[0m Trial 28 finished with value: 0.7675081147149431 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 699, 'min_child_samples': 160, 'reg_alpha': 10.0032036598533, 'reg_lambda': 13.961991896380587, 'num_leaves': 80, 'max_depth': 29, 'colsample_bytree': 0.6761169304215715, 'learning_rate': 0.02113814026709139}. Best is trial 25 with value: 0.768080775505045.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:24:35,285]\u001b[0m Trial 29 finished with value: 0.7650655768220034 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 810, 'min_child_samples': 182, 'reg_alpha': 12.205886170368338, 'reg_lambda': 13.450613963678066, 'num_leaves': 108, 'max_depth': 45, 'colsample_bytree': 0.7995558102106133, 'learning_rate': 0.02690441998496793}. Best is trial 25 with value: 0.768080775505045.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:25:48,929]\u001b[0m Trial 30 finished with value: 0.7643312505960586 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 637, 'min_child_samples': 161, 'reg_alpha': 13.48730461074433, 'reg_lambda': 14.580666659869202, 'num_leaves': 82, 'max_depth': 36, 'colsample_bytree': 0.7129644764956649, 'learning_rate': 0.008279369552953334}. Best is trial 25 with value: 0.768080775505045.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:26:59,786]\u001b[0m Trial 31 finished with value: 0.7670674014401153 and parameters: {'class_weight': {0: 1.0, 1: 13}, 'n_estimators': 721, 'min_child_samples': 150, 'reg_alpha': 11.031787095115568, 'reg_lambda': 14.224507575993739, 'num_leaves': 85, 'max_depth': 27, 'colsample_bytree': 0.6754471071792458, 'learning_rate': 0.023640396880082973}. Best is trial 25 with value: 0.768080775505045.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:27:58,591]\u001b[0m Trial 32 finished with value: 0.7682275349190192 and parameters: {'class_weight': 'balanced', 'n_estimators': 712, 'min_child_samples': 158, 'reg_alpha': 10.064359287829864, 'reg_lambda': 14.149358090618565, 'num_leaves': 56, 'max_depth': 15, 'colsample_bytree': 0.6362399728092023, 'learning_rate': 0.01742948669923419}. Best is trial 32 with value: 0.7682275349190192.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:28:51,157]\u001b[0m Trial 33 finished with value: 0.7666341717908188 and parameters: {'class_weight': 'balanced', 'n_estimators': 542, 'min_child_samples': 155, 'reg_alpha': 10.072128128558088, 'reg_lambda': 13.191404309452839, 'num_leaves': 56, 'max_depth': 14, 'colsample_bytree': 0.6388280856045633, 'learning_rate': 0.014373008475006195}. Best is trial 32 with value: 0.7682275349190192.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:29:48,957]\u001b[0m Trial 34 finished with value: 0.7683459294690801 and parameters: {'class_weight': 'balanced', 'n_estimators': 781, 'min_child_samples': 167, 'reg_alpha': 11.766191043484469, 'reg_lambda': 14.206551461816186, 'num_leaves': 54, 'max_depth': 16, 'colsample_bytree': 0.6296980381635193, 'learning_rate': 0.016921731098527678}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:30:43,314]\u001b[0m Trial 35 finished with value: 0.7668364420691572 and parameters: {'class_weight': 'balanced', 'n_estimators': 764, 'min_child_samples': 170, 'reg_alpha': 11.748249638926591, 'reg_lambda': 14.32817285721802, 'num_leaves': 35, 'max_depth': 17, 'colsample_bytree': 0.6257660869855683, 'learning_rate': 0.012586548962764132}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:31:56,880]\u001b[0m Trial 36 finished with value: 0.7614071841842283 and parameters: {'class_weight': 'balanced', 'n_estimators': 848, 'min_child_samples': 195, 'reg_alpha': 10.490607193966001, 'reg_lambda': 12.765806929080824, 'num_leaves': 49, 'max_depth': 9, 'colsample_bytree': 0.7012157110923886, 'learning_rate': 0.005545172014349155}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:33:41,877]\u001b[0m Trial 37 finished with value: 0.7667466861053025 and parameters: {'class_weight': {0: 1.0, 1: 19}, 'n_estimators': 943, 'min_child_samples': 164, 'reg_alpha': 10.998415738287063, 'reg_lambda': 14.150226773324677, 'num_leaves': 106, 'max_depth': 17, 'colsample_bytree': 0.6622287474464491, 'learning_rate': 0.01737151416267167}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:34:17,687]\u001b[0m Trial 38 finished with value: 0.7474012133181105 and parameters: {'class_weight': 'balanced', 'n_estimators': 798, 'min_child_samples': 181, 'reg_alpha': 11.741410576866269, 'reg_lambda': 13.257404641364053, 'num_leaves': 29, 'max_depth': 2, 'colsample_bytree': 0.9496981580736014, 'learning_rate': 0.010162630717260267}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:36:01,564]\u001b[0m Trial 39 finished with value: 0.7422047536918042 and parameters: {'class_weight': None, 'n_estimators': 759, 'min_child_samples': 167, 'reg_alpha': 10.488723471646052, 'reg_lambda': 14.9430536335143, 'num_leaves': 95, 'max_depth': 12, 'colsample_bytree': 0.7723376041270864, 'learning_rate': 0.0011376912450298989}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-29 01:36:36,962]\u001b[0m Trial 40 finished with value: 0.7669913489621383 and parameters: {'class_weight': 'balanced', 'n_estimators': 331, 'min_child_samples': 158, 'reg_alpha': 10.775108042042056, 'reg_lambda': 14.477806057132073, 'num_leaves': 74, 'max_depth': 25, 'colsample_bytree': 0.6232371636433602, 'learning_rate': 0.03906752143790038}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:37:27,917]\u001b[0m Trial 41 finished with value: 0.7674698356792335 and parameters: {'class_weight': {0: 1.0, 1: 16}, 'n_estimators': 649, 'min_child_samples': 154, 'reg_alpha': 13.01209097184585, 'reg_lambda': 13.691399894129871, 'num_leaves': 57, 'max_depth': 34, 'colsample_bytree': 0.6429349602276662, 'learning_rate': 0.018594156418477153}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:38:16,903]\u001b[0m Trial 42 finished with value: 0.7672295363591557 and parameters: {'class_weight': {0: 1.0, 1: 17}, 'n_estimators': 664, 'min_child_samples': 163, 'reg_alpha': 11.873630936553424, 'reg_lambda': 13.498838093482544, 'num_leaves': 56, 'max_depth': 17, 'colsample_bytree': 0.6236992044341101, 'learning_rate': 0.02370818352785429}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:39:02,980]\u001b[0m Trial 43 finished with value: 0.7663599678166507 and parameters: {'class_weight': {0: 1.0, 1: 15}, 'n_estimators': 591, 'min_child_samples': 168, 'reg_alpha': 11.151008313613069, 'reg_lambda': 13.996473550381328, 'num_leaves': 39, 'max_depth': 37, 'colsample_bytree': 0.6626341076021806, 'learning_rate': 0.015339015209095778}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:39:43,574]\u001b[0m Trial 44 finished with value: 0.7669910398901634 and parameters: {'class_weight': {0: 1.0, 1: 14}, 'n_estimators': 513, 'min_child_samples': 155, 'reg_alpha': 12.330429923951572, 'reg_lambda': 13.697677194373496, 'num_leaves': 49, 'max_depth': 30, 'colsample_bytree': 0.701442543295437, 'learning_rate': 0.03289196167273971}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:40:52,295]\u001b[0m Trial 45 finished with value: 0.7679706652166318 and parameters: {'class_weight': 'balanced', 'n_estimators': 884, 'min_child_samples': 150, 'reg_alpha': 11.542165725457249, 'reg_lambda': 12.867965264826855, 'num_leaves': 74, 'max_depth': 19, 'colsample_bytree': 0.617113872778073, 'learning_rate': 0.020843600653316842}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:42:06,273]\u001b[0m Trial 46 finished with value: 0.7671462469257534 and parameters: {'class_weight': 'balanced', 'n_estimators': 908, 'min_child_samples': 173, 'reg_alpha': 11.456613023798374, 'reg_lambda': 12.237516558001303, 'num_leaves': 74, 'max_depth': 19, 'colsample_bytree': 0.6830526602900632, 'learning_rate': 0.027070481612561904}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:43:21,457]\u001b[0m Trial 47 finished with value: 0.7662567614623 and parameters: {'class_weight': 'balanced', 'n_estimators': 847, 'min_child_samples': 161, 'reg_alpha': 12.072796966511799, 'reg_lambda': 12.89437253607993, 'num_leaves': 95, 'max_depth': 9, 'colsample_bytree': 0.6165105940893177, 'learning_rate': 0.009285394968116447}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:44:41,730]\u001b[0m Trial 48 finished with value: 0.7672110676475443 and parameters: {'class_weight': {0: 1.0, 1: 18}, 'n_estimators': 1078, 'min_child_samples': 168, 'reg_alpha': 10.236785113154077, 'reg_lambda': 12.776757134301858, 'num_leaves': 48, 'max_depth': 14, 'colsample_bytree': 0.7339568354197482, 'learning_rate': 0.012856646765612559}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n",
      "\u001b[32m[I 2020-12-29 01:45:54,826]\u001b[0m Trial 49 finished with value: 0.7634617169763732 and parameters: {'class_weight': 'balanced', 'n_estimators': 978, 'min_child_samples': 194, 'reg_alpha': 11.625528147084129, 'reg_lambda': 12.48205419396264, 'num_leaves': 25, 'max_depth': 11, 'colsample_bytree': 0.839284637944374, 'learning_rate': 0.007239578394916195}. Best is trial 34 with value: 0.7683459294690801.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Extracting the best model parameters and best study score\n",
    "best_study_score,best_study_params = study_best_score_params(X_train.values, y_train.values, lgb_c, objective_wrappper_lgbm, cv_strat,\n",
    "                                                            cl_weight, n_trials=50)\n",
    "# Used X_train.values & y_train.values as the some feature names had JSON characters , which were causing trouble \n",
    "# during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best roc_auc_score for the study is:  0.7683459294690801\n"
     ]
    }
   ],
   "source": [
    "print('The best roc_auc_score for the study is: ',best_study_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best study parameters for the classifier are:  {'class_weight': 'balanced', 'n_estimators': 781, 'min_child_samples': 167, 'reg_alpha': 11.766191043484469, 'reg_lambda': 14.206551461816186, 'num_leaves': 54, 'max_depth': 16, 'colsample_bytree': 0.6296980381635193, 'learning_rate': 0.016921731098527678}\n"
     ]
    }
   ],
   "source": [
    "print('The best study parameters for the classifier are: ',best_study_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the best tuned & more regularized LightGbm model by setting best study parameters.\n",
    "lgb_c = lgb_c.set_params(**best_study_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', colsample_bytree=0.6296980381635193,\n",
       "               learning_rate=0.016921731098527678, max_depth=16,\n",
       "               min_child_samples=167, n_estimators=781, n_jobs=5, num_leaves=54,\n",
       "               objective='binary', random_state=42,\n",
       "               reg_alpha=11.766191043484469, reg_lambda=14.206551461816186)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the best tuned  & more regularized lightgbm model on the Reduced feature training set\n",
    "lgb_c.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to calculate the roc_auc score for the feature sets\n",
    "def cal_roc_auc(X, y, cls, f_set, t_set, model_name):\n",
    "    ''' Calculates the roc auc score using the best study parameters \n",
    "        f_set : String: specifies 'full feature', 'Reduced feature'\n",
    "        t_set: String: specifies 'training', 'test'\n",
    "        model_name: String: specifies Name of the model '''\n",
    "        \n",
    "    y_pred = cls.predict_proba(X)\n",
    "    print('The roc_auc_score for the {} {} set using the best {} is '.format(f_set,t_set,model_name),roc_auc_score(y,y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the Reduced feature training set using the best updated Light Gbm is  0.8443935385323283\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Reduced feature training set roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_train.values, y_train, lgb_c, 'Reduced feature', 'training', 'updated Light Gbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the Reduced feature test set using the best updated Light Gbm is  0.7721968636105587\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Reduced feature test set roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_test.values, y_test, lgb_c, 'Reduced feature', 'test','updated Light Gbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating R_R ratio for the Light GBM Classifier_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the CV scores using sklearn's cross_val_score for more regularized light gbm classifier_2\n",
    "score_Light_Gbm_2 = cross_val_score(lgb_c, X_train.values, y_train, cv=cv_strat, n_jobs=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward associated with the Light GMB Classifier_2 using roc_auc metric is:  0.7683459294690801\n"
     ]
    }
   ],
   "source": [
    "print('The reward associated with the Light GMB Classifier_2 using roc_auc metric is: ',np.mean(score_Light_Gbm_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risk associated with the Light GMB Classifier_2 using roc_auc metric is:  0.00459052868738408\n"
     ]
    }
   ],
   "source": [
    "print('The risk associated with the Light GMB Classifier_2 using roc_auc metric is: ',np.std(score_Light_Gbm_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_R_Ratio_Light_Gbm_2 = np.mean(score_Light_Gbm_2)/np.std(score_Light_Gbm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward risk ratio for the best Light Gbm Classifier_2 using roc_auc metric is:  167.37634851965672\n"
     ]
    }
   ],
   "source": [
    "print('The reward risk ratio for the best Light Gbm Classifier_2 using roc_auc metric is: ',R_R_Ratio_Light_Gbm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold CV roc_auc scores for the light_gbm classifier_2 are:  [0.76351166 0.76321873 0.7754102  0.77069052 0.76889855]\n"
     ]
    }
   ],
   "source": [
    "print('5 fold CV roc_auc scores for the light_gbm classifier_2 are: ',score_Light_Gbm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Light_Gbm_2.joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the Reduced feature set best updated regularized  Light Gbm Classifier \n",
    "import joblib\n",
    "joblib.dump(lgb_c,'Light_Gbm_2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R_R Ratio for the more regularized Light Gbm classifier_2 using roc_auc metric is:  167.37634851965672"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "### 1) By making use of more regularization, Light Gbm classifier_2 has been able to substantially reduce overfitting as compared to that of Light Gbm classifier_1, with the test set roc_auc scores being almost equal for both of them.\n",
    "### 2) Further R_R ratio for the Light Gbm classifier_2 is marginally higher than that of Light Gbm classifier_1.\n",
    "### 3) Thus Light Gbm classifier_2 beats the Light Gbm classifier_1 hands down and has the best test set roc_auc as well as R_R ratio of all the models tested till now for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R_R Ratio for the best  Light Gbm classifier using roc_auc metric is:  167.37634851965672 , corresponding to more regularized Light Gbm classifier_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
