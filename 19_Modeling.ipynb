{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Required Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)# To see all the columns of a dataframe\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce the memory usage of various Dataframes\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "       \n",
    "        1. Iterate over every column\n",
    "        2. Determine if the column is numeric\n",
    "        3. Determine if the column can be represented by an integer\n",
    "        4. Find the min and the max value\n",
    "        5. Determine and apply the smallest datatype that can fit the range of values\n",
    "\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 181.24 MB\n",
      "Memory usage after optimization is: 38.27 MB\n",
      "Decreased by 78.9%\n"
     ]
    }
   ],
   "source": [
    "# Loading reduced feature training set\n",
    "X_train = import_data('X_train_final.csv')\n",
    "y_train = pd.read_csv('y_train.final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 60.41 MB\n",
      "Memory usage after optimization is: 12.76 MB\n",
      "Decreased by 78.9%\n"
     ]
    }
   ],
   "source": [
    "# Loading reduced feature test set\n",
    "X_test = import_data('X_test_final.csv')\n",
    "y_test = pd.read_csv('y_test.final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all the best models from various categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Joblib module\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing best Logistic regression Classifier\n",
    "lr = joblib.load('Log_Reg.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing best Random Forest Classifier\n",
    "rf = joblib.load('Rand_Forest_optuna_reg_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing best Light Gbm Classifier\n",
    "lgbm = joblib.load('Light_Gbm_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing best Linear Discriminant Analysis Classifier\n",
    "lda = joblib.load('Vanilla_lda.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_9: Voting Classifier with Default Weights & Soft_Voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Voting classifier from sklearn\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Sklearn's roc_auc_score module\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the voting Classifier Object\n",
    "voting_clf = VotingClassifier(estimators=[('logistic_Reg',lr),('Random_Forest',rf),('Light_Gbm',lgbm),\n",
    "                                           ('Linear_Dis',lda)],voting='soft',n_jobs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logistic_Reg',\n",
       "                              LogisticRegression(C=0.0031160262723627184,\n",
       "                                                 class_weight={0: 1.0, 1: 14},\n",
       "                                                 l1_ratio=0.4046164083668398,\n",
       "                                                 n_jobs=5, penalty='elasticnet',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='saga')),\n",
       "                             ('Random_Forest',\n",
       "                              RandomForestClassifier(class_weight={0: 1.0,\n",
       "                                                                   1: 13},\n",
       "                                                     max_depth=18,\n",
       "                                                     min_samples_leaf=0.0010028580411287713,\n",
       "                                                     n_estimators=570, n_jobs=5,\n",
       "                                                     ra...\n",
       "                             ('Light_Gbm',\n",
       "                              LGBMClassifier(class_weight='balanced',\n",
       "                                             colsample_bytree=0.6296980381635193,\n",
       "                                             learning_rate=0.016921731098527678,\n",
       "                                             max_depth=16,\n",
       "                                             min_child_samples=167,\n",
       "                                             n_estimators=781, n_jobs=5,\n",
       "                                             num_leaves=54, objective='binary',\n",
       "                                             random_state=42,\n",
       "                                             reg_alpha=11.766191043484469,\n",
       "                                             reg_lambda=14.206551461816186)),\n",
       "                             ('Linear_Dis', LinearDiscriminantAnalysis())],\n",
       "                 n_jobs=5, voting='soft')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the default voting classifier on the Reduced Feature Training set\n",
    "voting_clf.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the function to calculate the roc_auc score for the feature sets\n",
    "def cal_roc_auc(X, y, cls, f_set, t_set, model_name):\n",
    "    ''' Calculates the roc auc score using the best study parameters \n",
    "        f_set : String: specifies 'full feature', 'Reduced feature'\n",
    "        t_set: String: specifies 'training', 'test'\n",
    "        model_name: String: specifies Name of the model '''\n",
    "        \n",
    "    y_pred = cls.predict_proba(X)\n",
    "    print('The roc_auc_score for the {} {} set using the {} is '.format(f_set,t_set,model_name),roc_auc_score(y,y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature training set using the  default Voting Classifier is  0.8046460997742609\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature training set roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_train.values, y_train, voting_clf,'reduced feature','training',' default Voting Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature test set using the default Voting Classifier is  0.7664216167852927\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature test roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_test.values, y_test, voting_clf,'reduced feature','test','default Voting Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voting_default.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the default voting Classifier\n",
    "import joblib\n",
    "joblib.dump(voting_clf,'Voting_default.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating R_R ratio for default Voting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required Libraries\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Stratified K fold object\n",
    "cv_strat = StratifiedKFold(5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the CV scores using sklearn's cross_val_score\n",
    "score_voting_default = cross_val_score(voting_clf, X_train.values, y_train, cv=cv_strat, n_jobs=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward associated with the default Voting Classifier using roc_auc metric is:  0.7634440208535519\n"
     ]
    }
   ],
   "source": [
    "print('The reward associated with the default Voting Classifier using roc_auc metric is: ',np.mean(score_voting_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risk associated with the default Voting Classifier using roc_auc metric is:  0.004740966801500991\n"
     ]
    }
   ],
   "source": [
    "print('The risk associated with the default Voting Classifier using roc_auc metric is: ',np.std(score_voting_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_R_Ratio_voting_default = np.mean(score_voting_default)/np.std(score_voting_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward risk ratio for the default Voting Classifier using roc_auc metric is:  161.03129442118123\n"
     ]
    }
   ],
   "source": [
    "print('The reward risk ratio for the default Voting Classifier using roc_auc metric is: ',R_R_Ratio_voting_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voting_default.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the default voting Classifier\n",
    "import joblib\n",
    "joblib.dump(voting_clf,'Voting_default.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R_R Ratio for the default Voting classifier using roc_auc metric is: 161.03129442118123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation(s): \n",
    "### 1 The default voting classifier slightly overfits the dataset. May be hyperparameter tuning give better results.\n",
    "### 2) The test set roc_auc score for the default voting classifier is more than that of component Logistic Regression , LDA & Random Forest models, but less than that of  component Light GBM. May be tuning the weights of voting classifier result in better results.\n",
    "### 3) On the other hand, the R_R ratio for the default voting classifier model is more than those of component Logistic regression &  LDA models, but less than those of component Random forest & LightGBM models. So clearly LightGBM bests default Voting classifier hands down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_10: Voting Classifier with Tuned weights using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing  hyperparamater tuning optimizer optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a new voting classifier object\n",
    "voting_clf_2 = VotingClassifier(estimators=[('logistic_Reg',lr),('Random_Forest',rf),('Light_Gbm',lgbm),\n",
    "                                           ('Linear_Dis',lda)],voting='soft',n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the appropriate objective function for the best weights of Voting classifier.\n",
    "def objective_wrappper_Vt_2(X_tr, y_tr, cls=None, cv_strat=None):\n",
    "    '''\n",
    "    Optimizes voting classifier (cls) weights parameter on the given training set X_tr,y_tr\n",
    "    using Startified Cross Validation object cv_strat\n",
    "      \n",
    "    '''\n",
    "    \n",
    "    def objective(trial):\n",
    "        w1 = trial.suggest_uniform('w1',-1,1)\n",
    "        w2 = trial.suggest_uniform('w2',-1,1)\n",
    "        w3 = trial.suggest_uniform('w3',-1,1)\n",
    "        w4 = trial.suggest_uniform('w4',-1,1)\n",
    "        \n",
    "        params = {\n",
    "            'weights':[w1,w2,w3,w4]                 \n",
    "            }\n",
    "        \n",
    "        cls.set_params(**params)#Initializing the model with the parameter\n",
    "               \n",
    "        return np.mean(cross_val_score(cls, X_tr, y_tr, cv=cv_strat, n_jobs=5, scoring='roc_auc'))\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the best weights for the Voting Classifier_2 using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the evaluation function for study's best parameters\n",
    "def study_best_score_params(X_tr, y_tr, cls, obj_func, cv_strat, n_trials=50):\n",
    "    ''' Computes the best hyper parameters of the classsifier and returns \n",
    "    Optuna's study's best score & clasifier parameters'''\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(obj_func(X_tr, y_tr, cls, cv_strat), n_trials)\n",
    "    best_score = study.best_value\n",
    "    best_params = study.best_params\n",
    "    return (best_score,best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-02 22:42:11,653]\u001b[0m A new study created in memory with name: no-name-fddb9447-6269-434e-99b7-abd2c26e3f32\u001b[0m\n",
      "\u001b[32m[I 2021-01-02 22:52:12,920]\u001b[0m Trial 0 finished with value: 0.7584916705328142 and parameters: {'w1': 0.2909599590279115, 'w2': -0.6691209098646473, 'w3': -0.7251220701550498, 'w4': 0.2916882657943256}. Best is trial 0 with value: 0.7584916705328142.\u001b[0m\n",
      "\u001b[32m[I 2021-01-02 22:58:28,783]\u001b[0m Trial 1 finished with value: 0.7412433492892578 and parameters: {'w1': -0.853989929814851, 'w2': -0.13971544751084086, 'w3': 0.19613224534500429, 'w4': 0.2336487277016317}. Best is trial 0 with value: 0.7584916705328142.\u001b[0m\n",
      "\u001b[32m[I 2021-01-02 23:08:05,313]\u001b[0m Trial 2 finished with value: 0.40354532412477895 and parameters: {'w1': 0.8045767323509665, 'w2': -0.25248762510719014, 'w3': -0.3556876468814054, 'w4': -0.25565137159829177}. Best is trial 0 with value: 0.7584916705328142.\u001b[0m\n",
      "\u001b[32m[I 2021-01-02 23:17:54,578]\u001b[0m Trial 3 finished with value: 0.7629465414379971 and parameters: {'w1': 0.9979255001393559, 'w2': 0.6308369696819738, 'w3': 0.5493147628903121, 'w4': -0.25300247072357185}. Best is trial 3 with value: 0.7629465414379971.\u001b[0m\n",
      "\u001b[32m[I 2021-01-02 23:27:02,720]\u001b[0m Trial 4 finished with value: 0.7258729771016699 and parameters: {'w1': 0.25365814265755393, 'w2': -0.6911987267599171, 'w3': 0.11561325462826288, 'w4': -0.7359326499670529}. Best is trial 3 with value: 0.7629465414379971.\u001b[0m\n",
      "\u001b[32m[I 2021-01-02 23:36:51,832]\u001b[0m Trial 5 finished with value: 0.7655831138483545 and parameters: {'w1': 0.8315643704477713, 'w2': 0.6280635577979172, 'w3': 0.9923795757752982, 'w4': -0.6588990061747271}. Best is trial 5 with value: 0.7655831138483545.\u001b[0m\n",
      "\u001b[32m[I 2021-01-02 23:45:55,532]\u001b[0m Trial 6 finished with value: 0.7676879486520077 and parameters: {'w1': -0.14751882264091098, 'w2': 0.2847773742427384, 'w3': -0.9844422945489051, 'w4': -0.8136186119148365}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-02 23:55:03,448]\u001b[0m Trial 7 finished with value: 0.7599433737037151 and parameters: {'w1': 0.03667048462429112, 'w2': 0.6361781459875355, 'w3': 0.43883483588775696, 'w4': -0.3711228459475957}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 00:04:59,783]\u001b[0m Trial 8 finished with value: 0.7634953654826953 and parameters: {'w1': -0.7846350065120358, 'w2': 0.3510098253868028, 'w3': -0.5294942818809882, 'w4': 0.019846793433809795}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 00:13:54,282]\u001b[0m Trial 9 finished with value: 0.7621359912369038 and parameters: {'w1': -0.36802996731612225, 'w2': 0.4088370541683106, 'w3': 0.7754197294937026, 'w4': 0.0412879484029276}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 00:22:35,501]\u001b[0m Trial 10 finished with value: 0.7573272381539995 and parameters: {'w1': -0.4970953503759196, 'w2': 0.111564492159904, 'w3': -0.8873400786686891, 'w4': 0.9737303861757455}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 00:32:21,437]\u001b[0m Trial 11 finished with value: 0.6814315526775812 and parameters: {'w1': 0.570664452641131, 'w2': 0.965719292696153, 'w3': -0.3189437993963634, 'w4': -0.9997430148129848}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 00:41:14,095]\u001b[0m Trial 12 finished with value: 0.745726511260079 and parameters: {'w1': -0.3445712247241364, 'w2': 0.9870616625308314, 'w3': 0.9823551735933234, 'w4': -0.9499300621945844}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 00:51:04,817]\u001b[0m Trial 13 finished with value: 0.5766514183186202 and parameters: {'w1': -0.12851643166155124, 'w2': 0.6754770248154393, 'w3': -0.1386615464485865, 'w4': -0.633651001600174}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 01:00:54,910]\u001b[0m Trial 14 finished with value: 0.7658701909309936 and parameters: {'w1': 0.5502703070075439, 'w2': 0.25561717885712065, 'w3': 0.8523732133761843, 'w4': -0.6666670465750616}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 01:09:52,460]\u001b[0m Trial 15 finished with value: 0.34840520769692224 and parameters: {'w1': 0.5034862407512556, 'w2': 0.06346531111307424, 'w3': -0.9839027807848553, 'w4': 0.6970791958658838}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 01:18:30,689]\u001b[0m Trial 16 finished with value: 0.3336325555480718 and parameters: {'w1': -0.005043411550627819, 'w2': 0.28121764498345925, 'w3': 0.4181686769083194, 'w4': -0.9610235279672277}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 01:28:16,967]\u001b[0m Trial 17 finished with value: 0.756640325246541 and parameters: {'w1': 0.3394448441562488, 'w2': -0.4595935844902086, 'w3': 0.6900046754926888, 'w4': -0.4680694287066278}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 01:37:50,999]\u001b[0m Trial 18 finished with value: 0.7566713143776305 and parameters: {'w1': -0.5778855801000227, 'w2': -0.9989397647920838, 'w3': -0.06810758640456968, 'w4': -0.7922956978708695}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 01:46:40,945]\u001b[0m Trial 19 finished with value: 0.7671835663532869 and parameters: {'w1': -0.1418184743387001, 'w2': -0.11162537739836881, 'w3': -0.6623518133922526, 'w4': -0.5023188988742924}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 01:56:39,802]\u001b[0m Trial 20 finished with value: 0.7670196585379278 and parameters: {'w1': -0.19649781498524727, 'w2': -0.18885323509623653, 'w3': -0.7574809352598494, 'w4': -0.4951475722237832}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 02:06:09,561]\u001b[0m Trial 21 finished with value: 0.7670240959619556 and parameters: {'w1': -0.130312204723526, 'w2': -0.23696603175714726, 'w3': -0.733733770888712, 'w4': -0.47144980761543465}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 02:14:41,419]\u001b[0m Trial 22 finished with value: 0.7659933751486284 and parameters: {'w1': 0.07032767629355677, 'w2': -0.4082801049582685, 'w3': -0.6044936539191508, 'w4': -0.17175759755690562}. Best is trial 6 with value: 0.7676879486520077.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 02:23:27,420]\u001b[0m Trial 23 finished with value: 0.767866739648184 and parameters: {'w1': -0.18544651893192207, 'w2': -0.047168440983820614, 'w3': -0.9763917170992038, 'w4': -0.5111810113119644}. Best is trial 23 with value: 0.767866739648184.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 02:33:09,830]\u001b[0m Trial 24 finished with value: 0.7660432575227799 and parameters: {'w1': -0.6137421499950552, 'w2': -0.022761208113684095, 'w3': -0.9987089249650775, 'w4': -0.7986428570825648}. Best is trial 23 with value: 0.767866739648184.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 02:41:48,491]\u001b[0m Trial 25 finished with value: 0.7677930485874327 and parameters: {'w1': -0.2826269753036943, 'w2': 0.1792921472545268, 'w3': -0.9878154063213525, 'w4': -0.5539698589701034}. Best is trial 23 with value: 0.767866739648184.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 02:51:41,032]\u001b[0m Trial 26 finished with value: 0.7676857150304296 and parameters: {'w1': 0.16068590548646466, 'w2': 0.11582561373682898, 'w3': -0.8788198679059532, 'w4': -0.8449904785586222}. Best is trial 23 with value: 0.767866739648184.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 03:00:59,393]\u001b[0m Trial 27 finished with value: 0.7622971658709492 and parameters: {'w1': -0.3367968168701361, 'w2': 0.48344979438964764, 'w3': -0.470017894495416, 'w4': -0.1669181332281553}. Best is trial 23 with value: 0.767866739648184.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 03:09:42,551]\u001b[0m Trial 28 finished with value: 0.7656316071273406 and parameters: {'w1': -0.7059605580231254, 'w2': 0.2118236027706652, 'w3': -0.8708039102043945, 'w4': -0.5677385437825045}. Best is trial 23 with value: 0.767866739648184.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 03:19:21,751]\u001b[0m Trial 29 finished with value: 0.7577538481004477 and parameters: {'w1': -0.4570998203259191, 'w2': 0.7883042101198058, 'w3': -0.9612916614472541, 'w4': 0.44509084742502175}. Best is trial 23 with value: 0.767866739648184.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 03:28:16,542]\u001b[0m Trial 30 finished with value: 0.7663152585876702 and parameters: {'w1': -0.25677450915070876, 'w2': -0.4074861486425644, 'w3': -0.7693910188196995, 'w4': -0.3458192620364715}. Best is trial 23 with value: 0.767866739648184.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 03:38:41,163]\u001b[0m Trial 31 finished with value: 0.767345617517084 and parameters: {'w1': 0.18649111208932578, 'w2': 0.1518919329166348, 'w3': -0.8287162773015736, 'w4': -0.9011449604707698}. Best is trial 23 with value: 0.767866739648184.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 03:47:58,589]\u001b[0m Trial 32 finished with value: 0.7677674844146847 and parameters: {'w1': 0.12953540839802258, 'w2': -0.0803412748728825, 'w3': -0.9541124181143825, 'w4': -0.7991500924254487}. Best is trial 23 with value: 0.767866739648184.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 03:57:27,587]\u001b[0m Trial 33 finished with value: 0.7679089500995767 and parameters: {'w1': -0.03264723028188459, 'w2': -0.029930046315313815, 'w3': -0.9817864974187314, 'w4': -0.7289013094360486}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 04:06:10,324]\u001b[0m Trial 34 finished with value: 0.7674653910936595 and parameters: {'w1': -0.037984138971208725, 'w2': -0.029894363655682064, 'w3': -0.4048777834508386, 'w4': -0.3697355529003958}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 04:16:00,922]\u001b[0m Trial 35 finished with value: 0.7633695075959592 and parameters: {'w1': 0.380872848460186, 'w2': -0.07198492957584235, 'w3': -0.6355134900418695, 'w4': -0.6747491375767112}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 04:25:14,351]\u001b[0m Trial 36 finished with value: 0.7661879885114081 and parameters: {'w1': 0.1027707966126563, 'w2': -0.3038892817261794, 'w3': -0.9936327538570809, 'w4': 0.23860658552003175}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 04:35:32,925]\u001b[0m Trial 37 finished with value: 0.7660688521138503 and parameters: {'w1': -0.056701533436833346, 'w2': -0.5709691605484595, 'w3': -0.8728979326657647, 'w4': -0.5742373988574248}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 04:45:26,092]\u001b[0m Trial 38 finished with value: 0.7654965562518423 and parameters: {'w1': 0.2031286072821463, 'w2': -0.3264009034926384, 'w3': -0.5385359828489253, 'w4': -0.7272346489233014}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 04:55:05,603]\u001b[0m Trial 39 finished with value: 0.7610308182674916 and parameters: {'w1': -0.964224871106576, 'w2': -0.1578651325970606, 'w3': -0.328106711928166, 'w4': -0.053752876803220995}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 05:05:18,043]\u001b[0m Trial 40 finished with value: 0.7651242607912158 and parameters: {'w1': -0.20867998331066345, 'w2': 0.5159087827683031, 'w3': -0.6920392613704793, 'w4': -0.2845383617409768}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 05:14:32,405]\u001b[0m Trial 41 finished with value: 0.7671015913237094 and parameters: {'w1': -0.28378348114580193, 'w2': 0.023500872915247273, 'w3': -0.9940834136933575, 'w4': -0.890838928977566}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 05:23:49,045]\u001b[0m Trial 42 finished with value: 0.7666649187869277 and parameters: {'w1': -0.43599546624776564, 'w2': 0.2948469485537195, 'w3': -0.9365259013820483, 'w4': -0.761755201934706}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 05:33:54,526]\u001b[0m Trial 43 finished with value: 0.7670528646491684 and parameters: {'w1': -0.0728207878072257, 'w2': 0.39435307858907215, 'w3': -0.7997526437256934, 'w4': -0.5895708339807734}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 05:43:55,666]\u001b[0m Trial 44 finished with value: 0.7677282828024089 and parameters: {'w1': 0.07154114205473044, 'w2': 0.17491376469750614, 'w3': -0.9270180279770799, 'w4': -0.9793726209738711}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 05:53:12,532]\u001b[0m Trial 45 finished with value: 0.3061118850202891 and parameters: {'w1': 0.4370519917085609, 'w2': 0.047665340153284844, 'w3': 0.2387704572142848, 'w4': -0.9817680050972278}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 06:02:55,725]\u001b[0m Trial 46 finished with value: 0.7663149523364575 and parameters: {'w1': 0.2770413507175732, 'w2': 0.17210987218974083, 'w3': -0.9101494875086856, 'w4': -0.71205359910927}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 06:12:35,528]\u001b[0m Trial 47 finished with value: 0.7674563658333543 and parameters: {'w1': 0.0890648389829749, 'w2': -0.08736726755743282, 'w3': -0.7950890730675357, 'w4': -0.8700945955413444}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 06:21:39,704]\u001b[0m Trial 48 finished with value: 0.5715749650827577 and parameters: {'w1': 0.7067593603446596, 'w2': -0.20463983107321554, 'w3': -0.2154051184541328, 'w4': -0.9848462192097966}. Best is trial 33 with value: 0.7679089500995767.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 06:30:32,624]\u001b[0m Trial 49 finished with value: 0.7681115084496509 and parameters: {'w1': 0.03698328444546678, 'w2': 0.06481993464516658, 'w3': -0.5684888767601572, 'w4': -0.4152300140118141}. Best is trial 49 with value: 0.7681115084496509.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Extracting the best model parameters and best study score for the Voting Classifier_2\n",
    "best_study_score,best_study_params = study_best_score_params(X_train.values, y_train, voting_clf_2, objective_wrappper_Vt_2,\n",
    "                                                   cv_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best roc_auc_score for the study is:  0.7681115084496509\n"
     ]
    }
   ],
   "source": [
    "print('The best roc_auc_score for the study is: ',best_study_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best study parameters for the classifier are:  {'w1': 0.03698328444546678, 'w2': 0.06481993464516658, 'w3': -0.5684888767601572, 'w4': -0.4152300140118141}\n"
     ]
    }
   ],
   "source": [
    "print('The best study parameters for the classifier are: ',best_study_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the best tuned Voting clasiifier model by setting best study parameters.\n",
    "voting_clf_2 = voting_clf_2.set_params(weights=[best_study_params['w1'],best_study_params['w2'],\n",
    "                                                 best_study_params['w3'],best_study_params['w4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logistic_Reg',\n",
       "                              LogisticRegression(C=0.0031160262723627184,\n",
       "                                                 class_weight={0: 1.0, 1: 14},\n",
       "                                                 l1_ratio=0.4046164083668398,\n",
       "                                                 n_jobs=5, penalty='elasticnet',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='saga')),\n",
       "                             ('Random_Forest',\n",
       "                              RandomForestClassifier(class_weight={0: 1.0,\n",
       "                                                                   1: 13},\n",
       "                                                     max_depth=18,\n",
       "                                                     min_samples_leaf=0.0010028580411287713,\n",
       "                                                     n_estimators=570, n_jobs=5,\n",
       "                                                     ra...\n",
       "                                             learning_rate=0.016921731098527678,\n",
       "                                             max_depth=16,\n",
       "                                             min_child_samples=167,\n",
       "                                             n_estimators=781, n_jobs=5,\n",
       "                                             num_leaves=54, objective='binary',\n",
       "                                             random_state=42,\n",
       "                                             reg_alpha=11.766191043484469,\n",
       "                                             reg_lambda=14.206551461816186)),\n",
       "                             ('Linear_Dis', LinearDiscriminantAnalysis())],\n",
       "                 n_jobs=5, voting='soft',\n",
       "                 weights=[0.03698328444546678, 0.06481993464516658,\n",
       "                          -0.5684888767601572, -0.4152300140118141])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the best Voting Classifier on the reduced feature training set\n",
    "voting_clf_2.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature training set using the tuned Voting Classifier_2 is  0.835313505875434\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature training set roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_train.values, y_train, voting_clf_2, 'reduced feature', 'training', 'tuned Voting Classifier_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature test set using the tuned Voting Classifier_2 is  0.7718169510820518\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature test roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_test.values, y_test, voting_clf_2, 'reduced feature', 'test', 'tuned Voting Classifier_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voting_class_2.joblib']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the tuned voting Classifier\n",
    "import joblib\n",
    "joblib.dump(voting_clf_2,'Voting_class_2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating R_R ratio for  tuned  Voting Classifier_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the CV scores using sklearn's cross_val_score\n",
    "score_voting_2 = cross_val_score(voting_clf_2, X_train.values, y_train, cv=cv_strat, n_jobs=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward associated with the tuned Voting Classifier using roc_auc metric is:  0.7681115084496509\n"
     ]
    }
   ],
   "source": [
    "print('The reward associated with the tuned Voting Classifier using roc_auc metric is: ',np.mean(score_voting_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risk associated with the tuned Voting Classifier using roc_auc metric is:  0.004689520879208718\n"
     ]
    }
   ],
   "source": [
    "print('The risk associated with the tuned Voting Classifier using roc_auc metric is: ',np.std(score_voting_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_R_Ratio_voting_2 = np.mean(score_voting_2)/np.std(score_voting_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward risk ratio for the tuned Voting Classifier_2 using roc_auc metric is:  163.79317380910297\n"
     ]
    }
   ],
   "source": [
    "print('The reward risk ratio for the tuned Voting Classifier_2 using roc_auc metric is: ',R_R_Ratio_voting_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R_R Ratio for the tuned Voting classifier_2 using roc_auc metric is: 163.79317380910297"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation(s): \n",
    "### 1 The tuned voting classifier_2  clearly overfits the dataset, even more than the default version.\n",
    "### 2) The test set roc_auc score of the tuned voting classifier_2 is more than that of all component models (by a good margin ), but for that of the component Light  GBM and also exceeds that of untuned  default version.\n",
    "### 3) Further, the R_R ratio for the tuned voting classifier model is more than that of the default voting classifier, but still less than those of component Light Gbm and Random Forest classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets try to further reduce overfitting by incorporating more regularization & tuning another Voting Classifier_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a new voting classifier object\n",
    "voting_clf_3 = VotingClassifier(estimators=[('logistic_Reg',lr),('Random_Forest',rf),('Light_Gbm',lgbm),\n",
    "                                           ('Linear_Dis',lda)],voting='soft',n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the appropriate objective function for the best positive weights of Voting classifier.\n",
    "def objective_wrappper_Vt_3(X_tr, y_tr, cls=None, cv_strat=None):\n",
    "    '''\n",
    "    Optimizes voting classifier (cls) weights parameter on the given training set X_tr,y_tr\n",
    "    using Startified Cross Validation object cv_strat\n",
    "      \n",
    "    '''\n",
    "    \n",
    "    def objective(trial):\n",
    "        w1 = trial.suggest_uniform('w1',0,1)\n",
    "        w2 = trial.suggest_uniform('w2',0,1)\n",
    "        w3 = trial.suggest_uniform('w3',0,1)\n",
    "        w4 = trial.suggest_uniform('w4',0,1)\n",
    "        \n",
    "        params = {\n",
    "            'weights':[w1,w2,w3,w4]                 \n",
    "            }\n",
    "        \n",
    "        cls.set_params(**params)#Initializing the model with the parameter\n",
    "               \n",
    "        return np.mean(cross_val_score(cls, X_tr, y_tr, cv=cv_strat, n_jobs=5, scoring='roc_auc'))\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 16:17:20,425]\u001b[0m A new study created in memory with name: no-name-fa386478-8884-420c-a068-b82c3791a2df\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 16:26:52,137]\u001b[0m Trial 0 finished with value: 0.767001674343009 and parameters: {'w1': 0.10774709169418406, 'w2': 0.38599189026976755, 'w3': 0.8853934833368124, 'w4': 0.38023088614583844}. Best is trial 0 with value: 0.767001674343009.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 16:33:18,847]\u001b[0m Trial 1 finished with value: 0.7651768753272742 and parameters: {'w1': 0.6030994300522659, 'w2': 0.007367845048253496, 'w3': 0.6054506354708481, 'w4': 0.29620703388471237}. Best is trial 0 with value: 0.767001674343009.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 16:43:06,373]\u001b[0m Trial 2 finished with value: 0.7629358580486899 and parameters: {'w1': 0.44802670997137584, 'w2': 0.6872856666660636, 'w3': 0.47999145703522017, 'w4': 0.41705356716325026}. Best is trial 0 with value: 0.767001674343009.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 16:52:27,956]\u001b[0m Trial 3 finished with value: 0.7662861409995485 and parameters: {'w1': 0.1204096485118118, 'w2': 0.27891027757485976, 'w3': 0.6655475084218989, 'w4': 0.667954964677656}. Best is trial 0 with value: 0.767001674343009.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 17:02:14,857]\u001b[0m Trial 4 finished with value: 0.7588150753296198 and parameters: {'w1': 0.37045689703280804, 'w2': 0.8117693038379629, 'w3': 0.18894885944795614, 'w4': 0.9612792797849176}. Best is trial 0 with value: 0.767001674343009.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 17:11:39,022]\u001b[0m Trial 5 finished with value: 0.7633482683208123 and parameters: {'w1': 0.635485613259229, 'w2': 0.1885223545301853, 'w3': 0.4940584171298452, 'w4': 0.5765131274659318}. Best is trial 0 with value: 0.767001674343009.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 17:21:35,004]\u001b[0m Trial 6 finished with value: 0.7593628431408808 and parameters: {'w1': 0.6270328668038742, 'w2': 0.3984602698352323, 'w3': 0.1661255726594011, 'w4': 0.38873511405958183}. Best is trial 0 with value: 0.767001674343009.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 17:31:15,338]\u001b[0m Trial 7 finished with value: 0.7635576660349125 and parameters: {'w1': 0.03513639916243272, 'w2': 0.7905461942567643, 'w3': 0.5742248561393718, 'w4': 0.4014574408685564}. Best is trial 0 with value: 0.767001674343009.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 17:40:18,001]\u001b[0m Trial 8 finished with value: 0.7632916947531263 and parameters: {'w1': 0.5670982822795524, 'w2': 0.30490355177653183, 'w3': 0.43933573384760705, 'w4': 0.42658324418115245}. Best is trial 0 with value: 0.767001674343009.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 17:49:15,972]\u001b[0m Trial 9 finished with value: 0.7676128409278673 and parameters: {'w1': 0.09426346817967268, 'w2': 0.11725337874210329, 'w3': 0.5042486972266689, 'w4': 0.19095626823737166}. Best is trial 9 with value: 0.7676128409278673.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 17:59:33,595]\u001b[0m Trial 10 finished with value: 0.7656620907845838 and parameters: {'w1': 0.9985786500883791, 'w2': 0.047286957846718644, 'w3': 0.9441826760338867, 'w4': 0.007499937818703478}. Best is trial 9 with value: 0.7676128409278673.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 18:08:58,984]\u001b[0m Trial 11 finished with value: 0.7665424036386503 and parameters: {'w1': 0.24774253970555676, 'w2': 0.5613311727888568, 'w3': 0.94877429814262, 'w4': 0.1085282208663052}. Best is trial 9 with value: 0.7676128409278673.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 18:17:51,937]\u001b[0m Trial 12 finished with value: 0.7680850090054688 and parameters: {'w1': 0.004789547217768794, 'w2': 0.13196742228251707, 'w3': 0.7698089407440445, 'w4': 0.20589026892260995}. Best is trial 12 with value: 0.7680850090054688.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 18:26:59,342]\u001b[0m Trial 13 finished with value: 0.7681298325238373 and parameters: {'w1': 0.02118849842442312, 'w2': 0.12051505278777797, 'w3': 0.7580950418095982, 'w4': 0.19885111313073242}. Best is trial 13 with value: 0.7681298325238373.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 18:36:40,312]\u001b[0m Trial 14 finished with value: 0.7632852835852326 and parameters: {'w1': 0.9604562550425787, 'w2': 0.9868386438635064, 'w3': 0.7711107349573306, 'w4': 0.06311657021471953}. Best is trial 13 with value: 0.7681298325238373.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 18:46:07,580]\u001b[0m Trial 15 finished with value: 0.7674366414204802 and parameters: {'w1': 0.24537222211449844, 'w2': 0.18781214658743506, 'w3': 0.7742654930783833, 'w4': 0.20512298082544422}. Best is trial 13 with value: 0.7681298325238373.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 18:56:21,969]\u001b[0m Trial 16 finished with value: 0.7646390160962631 and parameters: {'w1': 0.756384767607056, 'w2': 0.005716033624065697, 'w3': 0.7843948915110757, 'w4': 0.746351501923006}. Best is trial 13 with value: 0.7681298325238373.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 19:05:51,139]\u001b[0m Trial 17 finished with value: 0.7629386939261285 and parameters: {'w1': 0.0005593194447997118, 'w2': 0.5092410051479519, 'w3': 0.32850946118856184, 'w4': 0.21133894860352426}. Best is trial 13 with value: 0.7681298325238373.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 19:15:37,157]\u001b[0m Trial 18 finished with value: 0.7671894808180645 and parameters: {'w1': 0.24181074625717458, 'w2': 0.23925850314151004, 'w3': 0.7008468218349178, 'w4': 0.12407301145149778}. Best is trial 13 with value: 0.7681298325238373.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 19:24:45,407]\u001b[0m Trial 19 finished with value: 0.7673633393733723 and parameters: {'w1': 0.3411743544056223, 'w2': 0.10777476396773567, 'w3': 0.8292259775545566, 'w4': 0.26453778403408634}. Best is trial 13 with value: 0.7681298325238373.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 19:34:27,078]\u001b[0m Trial 20 finished with value: 0.7596563381764598 and parameters: {'w1': 0.0013326141429497729, 'w2': 0.10334752133830652, 'w3': 0.03946922577862727, 'w4': 0.005350597185612288}. Best is trial 13 with value: 0.7681298325238373.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 19:43:06,218]\u001b[0m Trial 21 finished with value: 0.7669391780289436 and parameters: {'w1': 0.12041520889179506, 'w2': 0.12495424154477502, 'w3': 0.3780140983663818, 'w4': 0.16800034097417732}. Best is trial 13 with value: 0.7681298325238373.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 19:51:48,610]\u001b[0m Trial 22 finished with value: 0.7664546931546842 and parameters: {'w1': 0.07148044854220337, 'w2': 0.363489285026187, 'w3': 0.6304154144220264, 'w4': 0.3053176735480221}. Best is trial 13 with value: 0.7681298325238373.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 20:01:01,956]\u001b[0m Trial 23 finished with value: 0.7669104724789677 and parameters: {'w1': 0.17957264728634692, 'w2': 0.0027724337977748648, 'w3': 0.5666175390665372, 'w4': 0.5248799526767666}. Best is trial 13 with value: 0.7681298325238373.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 20:09:46,449]\u001b[0m Trial 24 finished with value: 0.7681490341404353 and parameters: {'w1': 0.024036256880662153, 'w2': 0.17003802965956968, 'w3': 0.987652769168206, 'w4': 0.07963149521862031}. Best is trial 24 with value: 0.7681490341404353.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 20:19:56,911]\u001b[0m Trial 25 finished with value: 0.7680586178272134 and parameters: {'w1': 0.1818573646829112, 'w2': 0.20446146248359198, 'w3': 0.9994951452920527, 'w4': 0.049976968039697395}. Best is trial 24 with value: 0.7681490341404353.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 20:29:10,292]\u001b[0m Trial 26 finished with value: 0.7674899043067444 and parameters: {'w1': 0.010559243341918384, 'w2': 0.32084767670969305, 'w3': 0.8852704106022455, 'w4': 0.11143327020262112}. Best is trial 24 with value: 0.7681490341404353.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 20:38:18,896]\u001b[0m Trial 27 finished with value: 0.7667137856111947 and parameters: {'w1': 0.32851476805806223, 'w2': 0.4560362630447952, 'w3': 0.9937266204800878, 'w4': 0.293908851153889}. Best is trial 24 with value: 0.7681490341404353.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 20:47:24,567]\u001b[0m Trial 28 finished with value: 0.765794089996663 and parameters: {'w1': 0.832904506372185, 'w2': 0.16693241986704846, 'w3': 0.8641816966990563, 'w4': 0.033506911051919525}. Best is trial 24 with value: 0.7681490341404353.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 20:56:55,846]\u001b[0m Trial 29 finished with value: 0.7679180159530394 and parameters: {'w1': 0.17897634752730665, 'w2': 0.0576560447405219, 'w3': 0.7121400485305807, 'w4': 0.24022243366904303}. Best is trial 24 with value: 0.7681490341404353.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:05:50,721]\u001b[0m Trial 30 finished with value: 0.7676862530779772 and parameters: {'w1': 0.051343856492023957, 'w2': 0.25325905988689734, 'w3': 0.9304608786085861, 'w4': 0.3461813341810904}. Best is trial 24 with value: 0.7681490341404353.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-03 21:14:31,673]\u001b[0m Trial 31 finished with value: 0.7680473701172844 and parameters: {'w1': 0.16673348359527287, 'w2': 0.2048822718166385, 'w3': 0.9936841271245903, 'w4': 0.08078247461755628}. Best is trial 24 with value: 0.7681490341404353.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:24:01,149]\u001b[0m Trial 32 finished with value: 0.768412265682939 and parameters: {'w1': 0.006035602899010558, 'w2': 0.04583130695137036, 'w3': 0.9898415019476203, 'w4': 0.15451161504144328}. Best is trial 32 with value: 0.768412265682939.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:33:21,203]\u001b[0m Trial 33 finished with value: 0.7684261743094537 and parameters: {'w1': 0.01862824610080053, 'w2': 0.03973089077337316, 'w3': 0.827427548199444, 'w4': 0.15565261694130678}. Best is trial 33 with value: 0.7684261743094537.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:42:08,486]\u001b[0m Trial 34 finished with value: 0.7684413153265106 and parameters: {'w1': 0.10395391465678885, 'w2': 0.04090546684700298, 'w3': 0.8452422937130442, 'w4': 0.13864802359714418}. Best is trial 34 with value: 0.7684413153265106.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 21:51:28,375]\u001b[0m Trial 35 finished with value: 0.768438640340091 and parameters: {'w1': 0.11235868451392766, 'w2': 0.05139126739336436, 'w3': 0.9041220689844103, 'w4': 0.1291435589304299}. Best is trial 34 with value: 0.7684413153265106.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 22:00:58,718]\u001b[0m Trial 36 finished with value: 0.7672949088484035 and parameters: {'w1': 0.44996263990152596, 'w2': 0.051012449347687956, 'w3': 0.8379146205847858, 'w4': 0.14698436991624178}. Best is trial 34 with value: 0.7684413153265106.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 22:11:07,481]\u001b[0m Trial 37 finished with value: 0.7673632309406655 and parameters: {'w1': 0.09710655066779658, 'w2': 0.0023311277858628077, 'w3': 0.9098763066432607, 'w4': 0.9502034112588826}. Best is trial 34 with value: 0.7684413153265106.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 22:20:19,797]\u001b[0m Trial 38 finished with value: 0.768163397449226 and parameters: {'w1': 0.12296975250305706, 'w2': 0.04735747984524552, 'w3': 0.8661930086343443, 'w4': 0.33003819741025137}. Best is trial 34 with value: 0.7684413153265106.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 22:29:16,861]\u001b[0m Trial 39 finished with value: 0.7668162961081932 and parameters: {'w1': 0.2930816571816897, 'w2': 0.06438596813364694, 'w3': 0.6960917588627087, 'w4': 0.47481366385984913}. Best is trial 34 with value: 0.7684413153265106.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 22:39:32,512]\u001b[0m Trial 40 finished with value: 0.767358717176361 and parameters: {'w1': 0.404168092845007, 'w2': 0.0007789510017108189, 'w3': 0.8302685853320706, 'w4': 0.25084496502132136}. Best is trial 34 with value: 0.7684413153265106.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 22:49:03,983]\u001b[0m Trial 41 finished with value: 0.7680912157922567 and parameters: {'w1': 0.13219657190610215, 'w2': 0.05967873848720325, 'w3': 0.8860051277866792, 'w4': 0.3581301569132504}. Best is trial 34 with value: 0.7684413153265106.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 22:58:47,610]\u001b[0m Trial 42 finished with value: 0.7683682395114206 and parameters: {'w1': 0.06949313651338616, 'w2': 0.02401445728552223, 'w3': 0.9332397207297387, 'w4': 0.3092407175407174}. Best is trial 34 with value: 0.7684413153265106.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 23:08:46,078]\u001b[0m Trial 43 finished with value: 0.7685422339897621 and parameters: {'w1': 0.07036755001796159, 'w2': 0.006986420679320118, 'w3': 0.9494789443218892, 'w4': 0.143312740080169}. Best is trial 43 with value: 0.7685422339897621.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 23:18:13,564]\u001b[0m Trial 44 finished with value: 0.7662211889967117 and parameters: {'w1': 0.2304221529521967, 'w2': 0.6721526547490553, 'w3': 0.9910511229720851, 'w4': 0.15554286864631423}. Best is trial 43 with value: 0.7685422339897621.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 23:28:06,594]\u001b[0m Trial 45 finished with value: 0.7683863287847534 and parameters: {'w1': 0.07396753759858328, 'w2': 0.08591347546960565, 'w3': 0.9596526383752937, 'w4': 0.13024554974976138}. Best is trial 43 with value: 0.7685422339897621.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 23:38:14,674]\u001b[0m Trial 46 finished with value: 0.768131223811813 and parameters: {'w1': 0.14532826285899528, 'w2': 0.15306618315556586, 'w3': 0.8124666601300988, 'w4': 0.014420550555417938}. Best is trial 43 with value: 0.7685422339897621.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 23:47:38,173]\u001b[0m Trial 47 finished with value: 0.768222248253214 and parameters: {'w1': 0.20724684482549294, 'w2': 0.09908375329538217, 'w3': 0.9033665530128853, 'w4': 0.08177521987422175}. Best is trial 43 with value: 0.7685422339897621.\u001b[0m\n",
      "\u001b[32m[I 2021-01-03 23:57:00,547]\u001b[0m Trial 48 finished with value: 0.7640052161202189 and parameters: {'w1': 0.2899127103708862, 'w2': 0.9453534227144762, 'w3': 0.735548756402296, 'w4': 0.24058782202320328}. Best is trial 43 with value: 0.7685422339897621.\u001b[0m\n",
      "\u001b[32m[I 2021-01-04 00:06:17,331]\u001b[0m Trial 49 finished with value: 0.7679483916942591 and parameters: {'w1': 0.049931288366462004, 'w2': 0.010724445668040192, 'w3': 0.9504411350396846, 'w4': 0.6807180788393391}. Best is trial 43 with value: 0.7685422339897621.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Extracting the best model parameters and best study score for the 2nd Voting Classifier\n",
    "best_study_score,best_study_params = study_best_score_params(X_train.values, y_train, voting_clf_3, objective_wrappper_Vt_3,\n",
    "                                                   cv_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best roc_auc_score for the study is:  0.7685422339897621\n"
     ]
    }
   ],
   "source": [
    "print('The best roc_auc_score for the study is: ',best_study_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The best study parameters for the classifier are: ', {'w1': 0.07036755001796159, 'w2': 0.006986420679320118, 'w3': 0.9494789443218892, 'w4': 0.143312740080169})\n"
     ]
    }
   ],
   "source": [
    "print(('The best study parameters for the classifier are: ',best_study_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the best tuned voting clasiifier model by setting best study parameters.\n",
    "voting_clf_3 = voting_clf_3.set_params(weights=[best_study_params['w1'],best_study_params['w2'],\n",
    "                                                 best_study_params['w3'],best_study_params['w4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logistic_Reg',\n",
       "                              LogisticRegression(C=0.0031160262723627184,\n",
       "                                                 class_weight={0: 1.0, 1: 14},\n",
       "                                                 l1_ratio=0.4046164083668398,\n",
       "                                                 n_jobs=5, penalty='elasticnet',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='saga')),\n",
       "                             ('Random_Forest',\n",
       "                              RandomForestClassifier(class_weight={0: 1.0,\n",
       "                                                                   1: 13},\n",
       "                                                     max_depth=18,\n",
       "                                                     min_samples_leaf=0.0010028580411287713,\n",
       "                                                     n_estimators=570, n_jobs=5,\n",
       "                                                     ra...\n",
       "                                             learning_rate=0.016921731098527678,\n",
       "                                             max_depth=16,\n",
       "                                             min_child_samples=167,\n",
       "                                             n_estimators=781, n_jobs=5,\n",
       "                                             num_leaves=54, objective='binary',\n",
       "                                             random_state=42,\n",
       "                                             reg_alpha=11.766191043484469,\n",
       "                                             reg_lambda=14.206551461816186)),\n",
       "                             ('Linear_Dis', LinearDiscriminantAnalysis())],\n",
       "                 n_jobs=5, voting='soft',\n",
       "                 weights=[0.07036755001796159, 0.006986420679320118,\n",
       "                          0.9494789443218892, 0.143312740080169])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the best tuned Voting Classifier_3 on the reduced feature training set.\n",
    "voting_clf_3.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature training set using the tuned Voting Classifier_3 is  0.8376093835249532\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature training set roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_train.values, y_train, voting_clf_3, 'reduced feature', 'training', 'tuned Voting Classifier_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature test set using the tuned Voting Classifier_3 is  0.7721661743865859\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature test set roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_test.values, y_test, voting_clf_3, 'reduced feature', 'test', 'tuned Voting Classifier_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voting_class_3.joblib']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the best voting Classifier_3\n",
    "import joblib\n",
    "joblib.dump(voting_clf_3,'Voting_class_3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating R_R ratio for the tuned Voting Classifier_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the CV scores using sklearn's cross_val_score\n",
    "score_voting_3 = cross_val_score(voting_clf_3, X_train.values, y_train, cv=cv_strat, n_jobs=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward associated with the tuned Voting Classifier_3 using roc_auc metric is:  0.7685422339897621\n"
     ]
    }
   ],
   "source": [
    "print('The reward associated with the tuned Voting Classifier_3 using roc_auc metric is: ',np.mean(score_voting_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risk associated with the tuned Voting Classifier_3 using roc_auc metric is:  0.004654394145759493\n"
     ]
    }
   ],
   "source": [
    "print('The risk associated with the tuned Voting Classifier_3 using roc_auc metric is: ',np.std(score_voting_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_R_Ratio_voting_3 = np.mean(score_voting_3)/np.std(score_voting_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward risk ratio for the tuned Voting Classifier_3 using roc_auc metric is:  165.12186332349236\n"
     ]
    }
   ],
   "source": [
    "print('The reward risk ratio for the tuned Voting Classifier_3 using roc_auc metric is: ',R_R_Ratio_voting_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold CV roc_auc scores for the tuned Voting Classifier_3 are:  [0.76345684 0.76346698 0.77567379 0.7708476  0.76926596]\n"
     ]
    }
   ],
   "source": [
    "print('5 fold CV roc_auc scores for the tuned Voting Classifier_3 are: ',score_voting_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R_R Ratio for the tuned Voting classifier_3 using roc_auc metric is: 165.12186332349236"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation(s): \n",
    "### 1 The tuned voting classifier_3  clearly overfits the dataset, even slightly more than the voting classifier_2.\n",
    "### 2) The test set roc_auc score of the tuned voting classifier_3 is again more than that of all component models (by a good margin ), but for that of the component Light  GBM and also exceeds those of both untuned  default version & Voting classifier_2\n",
    "### 3) Further, the R_R ratio for the tuned voting classifier_3 model is more than those of both voting classifier_2 & the default version , but still less than that of the component Random Forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best R_R Ratio for the voting classifier family using roc_auc metric is:  165.12186332349236 ,corresponding to tuned Voting Classifier_3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking everything into consideration, the tuned Voting Classifier_3 , even with slight overfitting, dominates all other voting classifiers & is clearly the best in the family of Voting Classifiers for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
